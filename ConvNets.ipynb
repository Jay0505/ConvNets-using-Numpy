{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validity_check(image, conv_filter, padding, stride):\n",
    "    \n",
    "    is_valid = True\n",
    "    image_shape = (np.shape(image))\n",
    "    print('image  - ' + str(image_shape))\n",
    "    filter_shape = (np.shape(conv_filter))\n",
    "    print('filter ' + str(filter_shape))\n",
    "    \n",
    "    \n",
    "    if len(image_shape) != len(filter_shape) - 1:\n",
    "        print('Dimensions of both image and filter should be equal')\n",
    "        is_valid = False\n",
    "    \n",
    "    if len(image_shape) == 3 or len(filter_shape) > 3:\n",
    "        if image_shape[-1] != filter_shape[-1]:\n",
    "            print('Number of channels in both image and filter should be equal')\n",
    "            is_valid = False\n",
    "        \n",
    "    if filter_shape[1] != filter_shape[2]:\n",
    "        print(\"Filter should be of a square matrix\")\n",
    "        is_valid = False\n",
    "        \n",
    "        \n",
    "\n",
    "    if filter_shape[1] % 2 == 0:\n",
    "        print('dimensions of filter should be of odd dimensions not even')\n",
    "        is_valid = False\n",
    "    \n",
    "\n",
    "    '''\n",
    "    convolution_result is the array we obtain after running the filter all over the image\n",
    "    '''    \n",
    "    if is_valid:\n",
    "        '''one or more filters but only one channel (also for image)'''\n",
    "        if len(image_shape) == 2 and len(filter_shape) == 3:\n",
    "            \n",
    "            convolution_result = np.zeros((\n",
    "                            np.int16(((image_shape[0] + 2 * padding - filter_shape[1]) / stride) + 1),\n",
    "                            np.int16(((image_shape[1] + 2 * padding - filter_shape[2]) / stride) + 1)))\n",
    "            \n",
    "        '''one or more filters with more than one channel (also for image)'''\n",
    "        if len(image_shape) == 3 and len(filter_shape) == 4:\n",
    "            convolution_result = np.zeros((\n",
    "                            np.int16(((image_shape[0] + 2 * padding - filter_shape[1]) / stride) + 1),\n",
    "                            np.int16(((image_shape[1] + 2 * padding - filter_shape[2]) / stride) + 1),\n",
    "                            image_shape[3]))\n",
    "    else:\n",
    "        convolution_result = -1\n",
    "    \n",
    "    return [is_valid, convolution_result]\n",
    "\n",
    "\n",
    "def Relu(x):\n",
    "    indices = np.where(x < 0)\n",
    "    x[indices] = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The dimensions represent height, width and no_of_channels in the input image and filters\n",
    "'''\n",
    "\n",
    "\n",
    "class Conv_pool:\n",
    "    '''\n",
    "    self.conv_result, self.pooling_result and self.relu_result  are of shape (m, n, o, p)\n",
    "    m - length of  conv_result (or pooling_result or relu_result) - no of images\n",
    "    n - number of different conv_results (produced by each filter in the input) or pooling_results \n",
    "    0 - number of rows in each entry in  conv_result (or pooling_result)\n",
    "    p - number of columns in each entry in conv_result (or pooling_result)\n",
    "    '''\n",
    "    def __init__(self, image, conv_filter, conv_bias, padding, stride, pooling_filter_size, pooling_filter_stride):\n",
    "        self.curr_image         = image\n",
    "        self.conv_filter        = conv_filter\n",
    "        self.conv_bias          = conv_bias\n",
    "        self.conv_filter_stride = stride\n",
    "        self.pool_filter_size   = pooling_filter_size\n",
    "        self.pool_filter_stride = pooling_filter_stride\n",
    "        self.padding            = padding\n",
    "        self.conv_result        = np.array([])\n",
    "        self.relu_result        = np.array([])\n",
    "        self.pooling_result     = np.array([])\n",
    "            \n",
    "    \n",
    "    \n",
    "    #####################################################\n",
    "    \n",
    "    def apply_convolution_every_image(self, convolution_result):\n",
    "        image        = self.curr_image\n",
    "        conv_filter  = self.conv_filter\n",
    "        stride       = self.conv_filter_stride\n",
    "        image_shape  = np.shape(image)\n",
    "        filter_shape = np.shape(conv_filter)\n",
    "        \n",
    "        no_of_filters         = filter_shape[0]\n",
    "        convoluted_image_list = []\n",
    "        \n",
    "        '''this loop runs for all the different filters in the conv_filter'''\n",
    "        for filter_num in range(0, no_of_filters):\n",
    "            convoluted_image = np.array([])\n",
    "            filter_ = conv_filter[filter_num, :]\n",
    "    \n",
    "            '''if image has more than one channel'''\n",
    "            if len(image_shape) == 3 and image_shape[-1] == filter_shape[-1]:\n",
    "\n",
    "                convoluted_image = self.convolve_the_image_by_filter(image[:, :, 0], filter_[:, :, 0], \n",
    "                                                                   convolution_result)\n",
    "                for channel in range(1, filter_shape[-1]):\n",
    "                    convoluted_image = convoluted_image + self.convolve_the_image_by_filter(image[:, :, channel], \n",
    "                                                                                             filter_[:, :, channel],\n",
    "                                                                                                 convolution_result)\n",
    "            '''if image has only one channel'''\n",
    "            if len(image_shape) == 2:\n",
    "                \n",
    "                convoluted_image = self.convolve_the_image_by_filter(image, filter_, convolution_result)\n",
    "            '''here, you used copy.copy() so as to refrain the convoluted_image_list getting over-written\n",
    "            by the new entries into the list'''\n",
    "            \n",
    "            convoluted_image = np.add(convoluted_image, self.conv_bias)\n",
    "            convoluted_image_list.append(copy.copy(convoluted_image))\n",
    "            \n",
    "        self.conv_result = np.array(convoluted_image_list)\n",
    "            \n",
    "    \n",
    "    \n",
    "    #########################################################\n",
    "    '''\n",
    "    when supplied with both image and filter, perform either convolution or pooling\n",
    "    '''\n",
    "    def apply_conv_or_pooling_on_data(self, image, filter_size, result, \n",
    "                                       stride_length, is_pooling, conv_filter = None):\n",
    "        \n",
    "        row_count = 0\n",
    "        column_count = 0\n",
    "\n",
    "        image_shape = np.shape(image)[1]\n",
    "        for row in range(0, image_shape, stride_length):\n",
    "            if row + filter_size <= image_shape:\n",
    "                column_count = 0\n",
    "                for column in range(0, image_shape, stride_length):\n",
    "\n",
    "                    if column + filter_size <= image_shape:\n",
    "                        \n",
    "                        '''present active region is the region in the image which will be multiplied\n",
    "                            by the filter'''\n",
    "                        if not is_pooling:\n",
    "                            \n",
    "                            present_active_region           = image[row : (row + filter_size), \n",
    "                                                                          column : (column + filter_size)]\n",
    "                            image_area_product_filter       = present_active_region * conv_filter\n",
    "                            sum_of_all_elements             = np.sum(image_area_product_filter)\n",
    "                            result[row_count, column_count] = sum_of_all_elements\n",
    "                        \n",
    "                        if is_pooling:\n",
    "                            \n",
    "                            active_region       = image[row : (row + filter_size), \n",
    "                                                                    column : (column + filter_size)] \n",
    "                            result[row_count, column_count] = np.max(active_region)\n",
    "\n",
    "                            \n",
    "                        column_count = column_count + 1\n",
    "            row_count = row_count + 1\n",
    "        \n",
    "        return result\n",
    "        \n",
    "        \n",
    "           \n",
    "    ######################################################\n",
    "    \n",
    "    def convolve_the_image_by_filter(self, image, conv_filter, convolution_result):\n",
    "        \n",
    "        stride      = self.conv_filter_stride\n",
    "        image_shape = np.shape(image)    \n",
    "        filter_size = np.shape(conv_filter)[0]\n",
    "        \n",
    "        result = self.apply_conv_or_pooling_on_data(image, filter_size, \n",
    "                                                    convolution_result, stride, False, conv_filter)\n",
    "        return result\n",
    "\n",
    "    \n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    def relu_on_convolution_result(self):\n",
    "        convolution_result_ = self.conv_result\n",
    "        \n",
    "        conv_result_shape            = np.shape(convolution_result_)\n",
    "        no_of_times_image_convoluted = conv_result_shape[0]\n",
    "        \n",
    "        \n",
    "            \n",
    "        relu_result_list = []\n",
    "\n",
    "        for result_num in range(0, no_of_times_image_convoluted):\n",
    "\n",
    "            current_convoluted_image = convolution_result_[result_num, :]\n",
    "            indices = np.where(current_convoluted_image <= 0)\n",
    "            current_convoluted_image[indices] = 0\n",
    "            relu_result_list.append(current_convoluted_image)\n",
    "\n",
    "        self.relu_result = np.array(relu_result_list)\n",
    "\n",
    "        \n",
    "    ######################################################\n",
    "    \n",
    "    '''max pooling'''    \n",
    "    def pooling_on_relu_result(self):\n",
    "        relu_result = self.relu_result\n",
    "        pool_size   = self.pool_filter_size\n",
    "        stride      = self.pool_filter_stride\n",
    "        \n",
    "\n",
    "        relu_result_shape            = np.shape(relu_result)\n",
    "        \n",
    "        no_of_relu_results_per_image = np.shape(relu_result)[0]\n",
    "        relu_result_shape_each_image = np.shape(relu_result)[1]\n",
    "\n",
    "        pooling_result_list = []\n",
    "        \n",
    "        \n",
    "    \n",
    "        for relu_result_num in range(0, no_of_relu_results_per_image):\n",
    "\n",
    "            curr_relu = relu_result[relu_result_num, :]\n",
    "\n",
    "            pooling_result   = np.zeros((np.uint16(((relu_result_shape_each_image - pool_size) / stride) + 1),\n",
    "                                   np.uint16(((relu_result_shape_each_image - pool_size) / stride) + 1)))\n",
    "\n",
    "            result = self.apply_conv_or_pooling_on_data(image = curr_relu, filter_size = pool_size, \n",
    "                                                        result = pooling_result, stride_length = stride, \n",
    "                                                        is_pooling = True)\n",
    "            pooling_result_list.append(result)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        self.pooling_result = np.array(pooling_result_list)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def pad_the_image(self):\n",
    "        pad_img = np.array()\n",
    "        if self.conv_filter.shape[1] == 3:\n",
    "            pad_img = np.zeros((30, 30))\n",
    "        \n",
    "        if self.conv_filter.shape[1] == 5:\n",
    "            pad_img = np.zeros((32, 32))\n",
    "            \n",
    "        pad_img[1 : self.curr_image.shape[1] + 1, 1 : self.curr_image.shape[1] + 1]  = self.curr_image\n",
    "        self.curr_image = pad_img\n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    def CNN(self):\n",
    "        \n",
    "        if self.padding:\n",
    "            self.pad_the_image()\n",
    "            \n",
    "        validity_convolution_result = validity_check(self.curr_image, self.conv_filter, \n",
    "                                                     self.padding, self.conv_filter_stride)\n",
    "        if validity_convolution_result[0]:\n",
    "            convolution_result = validity_convolution_result[1]\n",
    "            self.apply_convolution_every_image(convolution_result)\n",
    "            self.relu_on_convolution_result()\n",
    "            self.pooling_on_relu_result()\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu(x):\n",
    "    indices = np.where(x <= 0)\n",
    "    x[indices] = 0\n",
    "    return x\n",
    "    \n",
    "def softmax(x):\n",
    "    x = x.reshape(1, -1)\n",
    "    B = np.exp(x - max(x))\n",
    "    C = np.sum(B)\n",
    "    return B / C\n",
    "\n",
    "\n",
    "\n",
    "def cross_entropy(output, labels):\n",
    "    return -np.sum(labels * np.log(output))\n",
    "\n",
    "\n",
    "\n",
    "class fully_connected_layers_in_CNN:\n",
    "    \n",
    "    def __init__(self, conv_pool_object, labels, weights_1, weights_2, bias_1, bias_2, no_of_neurons):\n",
    "        self.conv_pool_result = conv_pool_object\n",
    "        self.pooling_result = conv_pool_object.pooling_result\n",
    "        self.labels = labels\n",
    "        self.pooling_result_shape = np.shape(self.pooling_result)\n",
    "        self.neurons = no_of_neurons\n",
    "    \n",
    "        self.weights_1 = weights_1\n",
    "        self.weights_2 = weights_2\n",
    "        self.bias_1    = bias_1\n",
    "        self.bias_2    = bias_2\n",
    "    ##########################################################\n",
    "    \n",
    "    def feed_forward_in_fc_layers(self):\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        pooling_result     = self.pooling_result\n",
    "        no_of_neurons      = self.neurons\n",
    "        print('shape ----- ' + str(self.pooling_result_shape))\n",
    "        no_of_pool_results = self.pooling_result_shape[0]\n",
    "        no_of_rows         = self.pooling_result_shape[1]\n",
    "        no_of_columns      = self.pooling_result_shape[2]\n",
    "        self.fc_layer_1    = pooling_result.reshape(((no_of_pool_results * no_of_rows * no_of_columns), 1))\n",
    "        \n",
    "#         no_of_rows_in_fc_layer_1 = self.fc_layer_1.shape[0]\n",
    "#         self.weights_1 = np.random.random((no_of_neurons[0], no_of_rows_in_fc_layer_1))\n",
    "#         self.bias_1 = np.zeros(shape = (no_of_neurons[0], 1))\n",
    "        print('w1 - ' + str(np.shape(w1)))\n",
    "        print('layer _1 - ' + str(np.shape(self.fc_layer_1)))\n",
    "        print('bias_1 - ' + str(np.shape(self.bias_1)))\n",
    "        self.z_1             = np.add(np.dot(self.weights_1.T, self.fc_layer_1), self.bias_1)\n",
    "        self.fc_layer_2      = Relu(self.z_1)\n",
    "        \n",
    "#         no_of_rows_in_fc_layer_2 = self.fc_layer_2.shape[0]\n",
    "#         self.weights_2 = np.random.random((no_of_neurons[1], no_of_rows_in_fc_layer_2))\n",
    "#         self.bias_2 = np.zeros(shape = (no_of_neurons[1], 1))\n",
    "        print('w2 - ' + str(np.shape(w2)))\n",
    "        print('layer _2 - ' + str(np.shape(self.fc_layer_2)))\n",
    "        print('bias_2 - ' + str(np.shape(self.bias_2)))\n",
    "        self.z_2             = np.add(np.dot(self.weights_2.T, self.fc_layer_2), self.bias_2)\n",
    "        self.predicted_probs = softmax(self.z_2)\n",
    "          \n",
    "        self.loss = cross_entropy(self.predicted_probs, self.labels)\n",
    "        self.diff_btw_pred_and_actual_labels = self.predicted_probs - self.labels\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class back_propagation_in_CNN:\n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def __init__(self, fc_layer_object):\n",
    "        self.fc_layer_object = fc_layer_object\n",
    "        self.conv_pool_result = fc_layer_object.conv_pool_result\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def get_the_index(self, conv_sub_array):\n",
    "        position_of_max_element = np.nanargmax(conv_sub_array)\n",
    "        index_of_max_element = np.unravel_index(position_of_max_element, conv_sub_array.shape)\n",
    "        return index_of_max_element\n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def backpropagation_wrt_pooling_result(self, derivative_pool_result):\n",
    "        \n",
    "        conv_result = self.conv_pool_result.conv_result\n",
    "        pool_filter_size = self.conv_pool_result.pool_filter_size\n",
    "        pool_filter_stride = self.conv_pool_result.pool_filter_stride\n",
    "        \n",
    "        no_of_convolved_images, no_of_rows, no_of_columns = np.shape(conv_result)\n",
    "        _, pool_row_length, _ = np.shape(derivative_pool_result)\n",
    "        output = np.zeros(shape = np.shape(conv_result))\n",
    "    \n",
    "        row_count = 0\n",
    "        column_count = 0\n",
    "        for image_num in range(0, no_of_convolved_images):\n",
    "            current_image = conv_result[image_num, :]\n",
    "            row_count = 0\n",
    "            for row in range(0, no_of_rows, pool_filter_stride):\n",
    "                if row + pool_filter_size <= no_of_rows:\n",
    "                    column_count = 0\n",
    "                    for column in range(0, no_of_columns, pool_filter_stride):\n",
    "                        if column + pool_filter_size <= no_of_columns:\n",
    "                            image_sub_array = current_image[row : row + pool_filter_size, column : column + pool_filter_size]\n",
    "                            '''index of the max element in the original conv_image (in the area covered by pool filter)'''\n",
    "                            (i, j) = self.get_the_index(image_sub_array)\n",
    "                            if row_count <= pool_row_length:\n",
    "                                output[image_num, row + i, column + j] = derivative_pool_result[image_num, \n",
    "                                                                                            row_count, column_count]\n",
    "                            column_count = column_count + 1\n",
    "                \n",
    "                row_count = row_count + 1\n",
    "            \n",
    "        return output\n",
    "                              \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def backpropagation_wrt_convolution_layer(self, der_conv_prev):\n",
    "                \n",
    "        conv_curr_image = self.conv_pool_result.curr_image\n",
    "        conv_image_curr_list = [conv_curr_image]\n",
    "        conv_image_curr = np.array(conv_image_curr_list)\n",
    "        conv_filter = self.conv_pool_result.conv_filter\n",
    "        filter_stride = self.conv_pool_result.conv_filter_stride\n",
    "        no_of_filters, flt_size, no_of_columns_f = np.shape(conv_filter)\n",
    "        \n",
    "        len_of_shape_of_curr_image = len(np.shape(conv_image_curr))\n",
    "        \n",
    "        _,no_of_rows, no_of_columns = np.shape(conv_image_curr)\n",
    "\n",
    "        \n",
    "        der_wrt_filter = np.zeros(np.shape(conv_filter))\n",
    "        der_wrt_bias = np.zeros((no_of_filters, 1))\n",
    "        dconv_result = np.zeros(np.shape(conv_image_curr))\n",
    "        \n",
    "        r_count = 0\n",
    "        c_count = 0\n",
    "        \n",
    "        for filter_num in range(0, no_of_filters, filter_stride):\n",
    "            r_count = 0\n",
    "            for r in range(0, no_of_rows):\n",
    "                if r + flt_size <= no_of_rows:\n",
    "                    c_count = 0\n",
    "                    for c in range(0, no_of_columns, filter_stride):\n",
    "                        if c + flt_size <= no_of_columns:\n",
    "                            '''update the filter'''\n",
    "                            \n",
    "                            der_wrt_filter += der_conv_prev[filter_num, r_count, c_count] * conv_image_curr[:, \n",
    "                                                                                                         r : r + flt_size,\n",
    "                                                                                                         c : c + flt_size]\n",
    "                            \n",
    "                            dconv_result[:, r : r + flt_size, c : c + flt_size] += der_conv_prev[filter_num, r_count, c_count] * conv_filter[filter_num, :]\n",
    "                            \n",
    "                            c_count = c_count + 1\n",
    "                r_count = r_count + 1\n",
    "        \n",
    "            der_wrt_bias[filter_num] = np.sum(der_conv_prev[filter_num])\n",
    "        \n",
    "        \n",
    "        return dconv_result, der_wrt_filter, der_wrt_bias\n",
    "                                \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def start_back_propagation(self):\n",
    "        \n",
    "        fc_layer_object = self.fc_layer_object\n",
    "        fc_layer_1      = fc_layer_object.fc_layer_1\n",
    "        \n",
    "        self.der_wrt_weights_2  = np.dot(fc_layer_object.diff_btw_pred_and_actual_labels.T, \n",
    "                                                       fc_layer_object.z_1.T)\n",
    "        \n",
    "        print('w2 - ' + str(np.shape(fc_layer_object.weights_2.T)))\n",
    "        print('diff - ' + str(np.shape(fc_layer_object.diff_btw_pred_and_actual_labels)))\n",
    "        print('layer_1 - ' + str(np.shape(fc_layer_object.fc_layer_1.T)))\n",
    "        print('bias_1 - ' + str(np.shape(fc_layer_object.bias_1.shape)))\n",
    "        \n",
    "        temporary_result = np.dot(fc_layer_object.weights_2,  \n",
    "                                  fc_layer_object.diff_btw_pred_and_actual_labels.T)\n",
    "        \n",
    "        self.der_wrt_weights_1 = np.dot(temporary_result, fc_layer_object.fc_layer_1.T)\n",
    "        \n",
    "        self.der_wrt_bias_2    = np.sum(fc_layer_object.diff_btw_pred_and_actual_labels, axis = 1).T\n",
    "        self.der_wrt_bias_1    = np.sum(temporary_result, axis = 1).reshape(fc_layer_object.bias_1.shape)\n",
    "        \n",
    "        \n",
    "        print('w1 - ' + str(np.shape(fc_layer_object.weights_1)))\n",
    "        print('pooling - ' + str(np.shape(fc_layer_object.pooling_result_shape)))\n",
    "        print('temporary - ' + str(np.shape(temporary_result)))\n",
    "        der_fc_layer_1 = np.dot(fc_layer_object.weights_1, temporary_result)\n",
    "        reshaped_dfc_layer_1 = der_fc_layer_1.reshape(fc_layer_object.pooling_result_shape)\n",
    "        \n",
    "        print('reshaped - ' + str(np.shape(reshaped_dfc_layer_1)))\n",
    "        '''back propagating through max-pooling layer (updating only those neurons with highest value)'''\n",
    "        der_pool_layer = self.backpropagation_wrt_pooling_result(reshaped_dfc_layer_1)\n",
    "        \n",
    "        '''back propagating through Relu layer'''\n",
    "        der_pool_layer[fc_layer_object.conv_pool_result.conv_result <= 0] = 0\n",
    "        \n",
    "        der_image, der_filter, der_conv_bias = self.backpropagation_wrt_convolution_layer(der_pool_layer)\n",
    "        \n",
    "        self.return_result = [der_filter, der_conv_bias]\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########################################################\n",
    "def read_data(directory_path, is_train_data):\n",
    "    if is_train_data:\n",
    "        mnsit_data = pd.read_csv(directory_path, header=None, low_memory = False)\n",
    "        mnsit_data.drop(0, axis = 0, inplace = True)\n",
    "        train_Y    = mnsit_data[0].astype(np.float32)\n",
    "        mnsit_data.drop(0, axis = 1, inplace = True)\n",
    "        mnsit_data = mnsit_data.astype(np.float32)\n",
    "\n",
    "        return mnsit_data, train_Y\n",
    "    \n",
    "    else:\n",
    "        mnsit_test = pd.read_csv(directory_path, header = None, low_memory = False)\n",
    "        mnsit_test.drop(0, axis = 0, inplace = True)\n",
    "        mnsit_test = mnsit_test.astype(np.float32)\n",
    "        \n",
    "        return mnsit_test\n",
    "    \n",
    "    \n",
    "    \n",
    "##########################################################\n",
    "def split_the_train_data(train_X, train_Y):\n",
    "    train_x, train_y, test_x, test_y = train_test_split(train_X, train_Y, test_size = 0.2, \n",
    "                                                        random_state = 42)\n",
    "    \n",
    "    return [[train_x, test_x], [train_y, test_y]]\n",
    "    \n",
    "##########################################################\n",
    "def convert_labels_to_one_hot_encoding_format(train_y, test_y):\n",
    "    one_hot_encoder = OneHotEncoder(categories = 'auto')\n",
    "    train_y_encoded = one_hot_encoder.fit_transform(train_y).toarray()\n",
    "    test_y_encoded  = one_hot_encoder.fit_transform(test_y).toarray()\n",
    "    return train_y_encoded.astype(np.float32), test_y_encoded.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# def convert_input_to_image_format(row):\n",
    "#     return row.values.reshape(28, 28)\n",
    "def convert_input_to_image_format(data):\n",
    "    output = []\n",
    "    no_of_rows = np.shape(data)[0]\n",
    "    for row_num in range(0, no_of_rows):\n",
    "        output.append(data.iloc[row_num].values.reshape(28, 28))\n",
    "    \n",
    "    return np.array(output).astype(np.float32)\n",
    "    \n",
    "\n",
    "\n",
    "##########################################################\n",
    "def standardize_the_data(train_data, test_data):\n",
    "    scaler = StandardScaler().fit(train_data)\n",
    "    train_data_scaled = scaler.transform(train_data)\n",
    "    test_data_scaled  = scaler.transform(test_data)\n",
    "    return pd.DataFrame(train_data_scaled, dtype = np.float32), pd.DataFrame(test_data_scaled, dtype = np.float32)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow-session/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/envs/tensorflow-session/lib/python3.6/site-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
      "/anaconda3/envs/tensorflow-session/lib/python3.6/site-packages/ipykernel_launcher.py:55: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "train_X, train_Y = read_data('/Users/vijay/Downloads/digit-recognizer/train.csv', True)\n",
    "test_X           = read_data('/Users/vijay/Downloads/digit-recognizer/test.csv', False)\n",
    "\n",
    "train_test_data  = split_the_train_data(train_X, train_Y)\n",
    "train_x, train_y = train_test_data[0]\n",
    "test_x, test_y   = train_test_data[1]\n",
    "\n",
    "train_x_standardized, test_x_standardized = standardize_the_data(train_x, test_x)\n",
    "# train_x_reshaped = train_x_standardized.apply(convert_input_to_image_format, axis = 1)\n",
    "# test_x_reshape   = test_x_standardized.apply(convert_input_to_image_format, axis = 1)\n",
    "train_x_reshaped = convert_input_to_image_format(train_x_standardized)\n",
    "test_x_reshaped   = convert_input_to_image_format(test_x_standardized)\n",
    "\n",
    "train_y_encoded, test_y_encoded = convert_labels_to_one_hot_encoding_format(train_y.values.reshape(-1, 1), \n",
    "                                                                           test_y.values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "del(train_x)\n",
    "del(test_x)\n",
    "del(train_y)\n",
    "del(test_y)\n",
    "del(train_x_standardized)\n",
    "del(test_x_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_filter = np.zeros((2,3,3))\n",
    "\n",
    "l1_filter[0, :, :] = np.array([[[-1, 0, 1],   \n",
    "                                  [-1, 0, 1],   \n",
    "                                   [-1, 0, 1]]])  \n",
    "l1_filter[1, :, :] = np.array([[[1,   1,  1],   \n",
    "                                   [0,   0,  0],   \n",
    "                                    [-1, -1, -1]]]) \n",
    "\n",
    "\n",
    "sample_x = train_x_reshaped[0]\n",
    "sample_y = train_y_encoded[0]\n",
    "\n",
    "np.shape(sample_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_filters = get_filters_for_convolution(3, 32, 1)\n",
    "w1, w2       = get_weights_for_fc_layers(2, 28, 3, 2, 1, 2, 1, 0, [52, 10])\n",
    "conv_bias    = get_biases_for_convolution(26)\n",
    "b1, b2       = get_biases_for_fc_layers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image  - (28, 28)\n",
      "filter (2, 3, 3)\n",
      "2\n",
      "shape ----- (32, 13, 13)\n",
      "w1 - (338, 52)\n",
      "layer _1 - (5408, 1)\n",
      "bias_1 - (1024, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (52,338) and (5408,1) not aligned: 338 (dim 1) != 5408 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-85bc1b8f4a31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconv_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfc_layer\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mfully_connected_layers_in_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m52\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfc_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_in_fc_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-148-a37376b37afd>\u001b[0m in \u001b[0;36mfeed_forward_in_fc_layers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'layer _1 - '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layer_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias_1 - '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_1\u001b[0m             \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layer_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layer_2\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mRelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (52,338) and (5408,1) not aligned: 338 (dim 1) != 5408 (dim 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "conv_pool = Conv_pool(sample_x, l1_filter, conv_bias, 0, 1, 2, 2)\n",
    "conv_pool.CNN()\n",
    "fc_layer  = fully_connected_layers_in_CNN(cnn, sample_y, w1, w2, b1, b2, [52, 10]) \n",
    "fc_layer.feed_forward_in_fc_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2 - (10, 1024)\n",
      "diff - (1, 10)\n",
      "layer_1 - (1, 5408)\n",
      "bias_1 - (2,)\n",
      "w1 - (5408, 1024)\n",
      "pooling - (3,)\n",
      "temporary - (1024, 1)\n",
      "reshaped - (32, 13, 13)\n"
     ]
    }
   ],
   "source": [
    "bp = back_propagation_in_CNN(fc_layer)\n",
    "bp.start_back_propagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]],\n",
       " \n",
       "        [[-5439.60433114, -7821.41096778, -7573.79837336],\n",
       "         [-8304.67211947, -9297.92974907, -8571.8787772 ],\n",
       "         [-6921.8641906 , -7868.69019476, -6973.13138385]]]),\n",
       " array([[-371.30172155],\n",
       "        [-444.53861529],\n",
       "        [-385.9078015 ],\n",
       "        [-486.09797498],\n",
       "        [-384.93724239],\n",
       "        [-444.87785123],\n",
       "        [-435.63731116],\n",
       "        [-424.06062641],\n",
       "        [-436.94239984],\n",
       "        [-407.57116017],\n",
       "        [-396.43543368],\n",
       "        [-402.36365846],\n",
       "        [-459.42605147],\n",
       "        [-446.98103565],\n",
       "        [-382.12246723],\n",
       "        [-436.69201243],\n",
       "        [-458.28509253],\n",
       "        [-398.04551348],\n",
       "        [-387.37400863],\n",
       "        [-474.92247574],\n",
       "        [-446.0329935 ],\n",
       "        [-427.83917143],\n",
       "        [-416.70073501],\n",
       "        [-392.01065601],\n",
       "        [-417.93305406],\n",
       "        [-437.45418126],\n",
       "        [-424.76289747],\n",
       "        [-462.26827182],\n",
       "        [-455.3202134 ],\n",
       "        [-424.69520348],\n",
       "        [-432.21061537],\n",
       "        [-395.81908287]])]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.return_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_filters_for_convolution(filter_size, no_of_filters, no_of_channels):\n",
    "    \n",
    "    if no_of_channels == 1:\n",
    "        conv_filters = np.zeros((no_of_filters, filter_size, filter_size))\n",
    "        for i in range(0, no_of_filters):\n",
    "            \n",
    "            filter_ = np.random.random((filter_size, filter_size))\n",
    "            conv_filters[i, :, :] = filter_\n",
    "            \n",
    "        return conv_filters\n",
    "    else:\n",
    "        conv_filters = np.zeros((no_of_filters, filter_size, filter_size, no_of_channels))\n",
    "        \n",
    "        for i in range(0, no_of_filters):\n",
    "            filter_ = np.random.random((filter_size, filter_size, no_of_channels))\n",
    "            conv_filters[i, :, :, :] = filter_\n",
    "\n",
    "        return conv_filters\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "def get_weights_for_fc_layers(no_of_filters, image_size, conv_f_size, \n",
    "                                 pool_size, conv_f_stride, pool_stride, no_of_convolutions, padding, no_of_neurons):\n",
    "    for num in range(0, no_of_convolutions):\n",
    "        \n",
    "        conv_size  = np.int16(((image_size + 2 * padding - conv_f_size) / conv_f_stride) + 1)\n",
    "        pool_size  = np.uint16(((conv_size - pool_size) / pool_stride) + 1)\n",
    "        image_size = pool_size\n",
    "    \n",
    "    \n",
    "    weights_1 = np.random.random(((no_of_filters * image_size * image_size), no_of_neurons[0]))\n",
    "    weights_2 = np.random.random((no_of_neurons[0], no_of_neurons[1]))\n",
    "    \n",
    "    return weights_1, weights_2\n",
    "    \n",
    "\n",
    "def get_biases_for_convolution(filter_size):\n",
    "    conv_bias = np.full((filter_size, filter_size), 0.1)\n",
    "    return conv_bias\n",
    "    \n",
    "\n",
    "def get_biases_for_fc_layers():\n",
    "    bias_1 = np.random.random((52, 1))\n",
    "    bias_2 = np.random.random((10, 1))\n",
    "    \n",
    "    return bias_1, bias_2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 336\n",
    "\n",
    "def update_parameters_for_each_batch(train_x, train_y, beta1, beta2, learning_rate, parameters, pooling_filter_size,\n",
    "                                        pooling_filter_stride, padding, stride, loss):\n",
    "    \n",
    "    cf, cb, w1, w2, b1, b2 = parameters\n",
    "    conv_filter_shape = np.shape(cf)\n",
    "    conv_bias_shape   = np.shape(cb)\n",
    "    weights_1_shape   = np.shape(w1)\n",
    "    weights_2_shape   = np.shape(w2)\n",
    "    bias_1_shape      = np.shape(b1)\n",
    "    bias_2_shape      = np.shape(b2)\n",
    "    \n",
    "    \n",
    "    loss_       = 0\n",
    "    cov_filter_ = np.zeros(conv_filter_shape)\n",
    "    conv_bias_  = np.zeros(conv_bias_shape) \n",
    "    weights_1_  = np.zeros(weights_1_shape)\n",
    "    weights_2_  = np.zeros(weights_2_shape)\n",
    "    bias_1_     = np.zeros(bias_1_shape)\n",
    "    bias_2_     = np.zeros(bias_2_shape)\n",
    "\n",
    "    v_cf   = np.zeros(conv_filter_shape)\n",
    "    v_w_1  = np.zeros(weights_1_shape)\n",
    "    v_w_2  = np.zeros(weights_2_shape)\n",
    "    v_cb   = np.zeros(conv_bias_shape)\n",
    "    v_w1_b = np.zeros(bias_1_shape)\n",
    "    v_w2_b = np.zeros(bias_2_shape)\n",
    "\n",
    "    u_cf   = np.zeros(conv_filter_shape)\n",
    "    u_w_1  = np.zeros(weights_1_shape)\n",
    "    u_w_2  = np.zeros(weights_2_shape)\n",
    "    u_cb   = np.zeros(conv_bias_shape)\n",
    "    u_w1_b = np.zeros(bias_1_shape)\n",
    "    u_w2_b = np.zeros(bias_2_shape)\n",
    "\n",
    "\n",
    "\n",
    "    for image_num in range(0, batch_size):\n",
    "\n",
    "        conv_pool_object = Conv_pool(train_x[image_num], cf, cb, padding = 0, stride = 1, \n",
    "                                                    pooling_filter_size = 2, pooling_filter_stride = 2)\n",
    "        fc_layer_object  = fully_connected_layers_in_CNN(conv_pool_object, train_y[image_num], \n",
    "                                                         w1, w2, b1, b2, [1024, 10]).feed_forward_in_fc_layers()\n",
    "        bp_object        = back_propagation_in_CNN(fc_layer_object).start_back_propagation()\n",
    "\n",
    "\n",
    "        d_conv_filter, d_conv_bias  = bp_object.return_result\n",
    "        d_wt_1, d_wt_2              = bp_object.der_weights_1, db_object.der_weights_2, \n",
    "        d_bias_1, d_bias_2          = bp_object.der_bias_1, bp_object.der_bias_1\n",
    "\n",
    "        conv_filter_ += d_conv_filter\n",
    "        conv_bias_   += d_conv_bias\n",
    "        weights_1_   += d_wt_1\n",
    "        weights_2_   += d_wt_2\n",
    "        bias_1_      += d_bias_1\n",
    "        bias_2_      += d_bias_2\n",
    "        loss_        += fc_layer_object.loss\n",
    "            \n",
    "            \n",
    "            \n",
    "        v_cf = beta1 * v_cf + (1 - beta1) * (conv_filter_ / batch_size) \n",
    "        u_cf = beta2 * u_cg + (1 - beta2) * (conv_filter_ / batch_size) ** 2\n",
    "        cf  -= learning_rate * v_cf / np.sqrt(u_cg + 1e-7)\n",
    "\n",
    "        v_cb = beta1 * v_cb + (1 - beta1) * conv_bias_ / batch_size\n",
    "        u_cb = beta2 * u_cb + (1 - beta2) * (conv_bias_ / batch_size) ** 2\n",
    "        cb  -= learning_rate * v_cb / np.sqrt(u_cb + 1e-7)\n",
    "\n",
    "        v_w_1 = beta1 * v_w_1 + (1 - beta1) * weights_1_ / batch_size\n",
    "        u_w_1 = beta2 * u_w_1 + (1 - beta2) * (weights_1_ / batch_size) ** 2\n",
    "        w1   -= learning_rate * v_w_1/np.sqrt(u_w_1 + 1e-7)\n",
    "\n",
    "        v_w_2 = beta1 * v_w_2 + (1 - beta1) * weights_2_ / batch_size\n",
    "        u_w_2 = beta2 * u_w_2 + (1 - beta2) * (weights_2_ / batch_size) ** 2\n",
    "        w2   -= learning_rate * v_w_2/np.sqrt(u_w_2 + 1e-7)\n",
    "\n",
    "\n",
    "        v_w1_b = beta1 * v_w1_b + (1 - beta1) * bias_1_ / batch_size\n",
    "        u_w1_b = beta2 * u_w1_b + (1 - beta2) * (bias_1_ / batch_size) ** 2\n",
    "        b1    -= learning_rate * v_w1_b/np.sqrt(u_w1_b+1e-7)\n",
    "\n",
    "        v_w2_b = beta1 * v_w2_b + (1 - beta1) * bias_2_ / batch_size\n",
    "        u_w2_b = beta2 * u_w2_b + (1 - beta2) * (bias_2_ / batch_size) ** 2\n",
    "        b2    -= learning_rate * v_w2_b/np.sqrt(u_w2_b+1e-7)\n",
    "        \n",
    "        loss_ = loss_ / batch_size\n",
    "        loss.append(loss_)\n",
    "        parameters = [cf, cb, w1, w2, b1, b2] \n",
    "        \n",
    "        \n",
    "        return parameters, loss\n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "def train(X, Y, img_size = 28, no_of_channels = 1, lr = 0.01, beta1 = 0.95, beta2 =0.99, \n",
    "                                    no_of_conv_filter = 8, batch_size = 50, no_of_epochs = 5):\n",
    "    \n",
    "    conv_filter = get_filters_for_convolution(filter_size = 3, no_of_filters = 32, no_of_channels = 1)\n",
    "    conv_bias   = get_biases_for_convolution(3)\n",
    "\n",
    "    weights_1, weights_2 = get_weights_for_fc_layers(32, 28, 3, 2, 1, 2, 1, 0, [1024, 10])\n",
    "    bias_1, bias_2       = get_biases_for_fc_layers()\n",
    "    \n",
    "    parameters = [conv_filter, conv_bias, weights_1, weights_2, bias_1, bias_2]\n",
    "    loss = []\n",
    "    no_of_rows = len(X)\n",
    "    \n",
    "    \n",
    "    for epoch in range(0, no_of_epochs):\n",
    "        X, Y = shuffle(X, Y)\n",
    "    for row in range(0, no_of_rows, batch_size):\n",
    "        train_x = X[row : row + batch_size, :]\n",
    "        train_y  = Y[row : row + batch_size, :]\n",
    "        parameters, loss = update_parameters_for_each_batch(train_x, train_y, beta1, beta2, lr, parameters, \n",
    "                                                             2, 2, 0, 1, loss)\n",
    "    \n",
    "        \n",
    "    return parameters, loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape ----- (0,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-73f23a7a40f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-b2a56d25c0a9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X, Y, img_size, no_of_channels, lr, beta1, beta2, no_of_conv_filter, batch_size, no_of_epochs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mtrain_y\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         parameters, loss = update_parameters_for_each_batch(train_x, train_y, beta1, beta2, lr, parameters, \n\u001b[0;32m--> 118\u001b[0;31m                                                              2, 2, 0, 1, loss)\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-b2a56d25c0a9>\u001b[0m in \u001b[0;36mupdate_parameters_for_each_batch\u001b[0;34m(train_x, train_y, beta1, beta2, learning_rate, parameters, pooling_filter_size, pooling_filter_stride, padding, stride, loss)\u001b[0m\n\u001b[1;32m     42\u001b[0m                                                     pooling_filter_size = 2, pooling_filter_stride = 2)\n\u001b[1;32m     43\u001b[0m         fc_layer_object  = fully_connected_layers_in_CNN(conv_pool_object, train_y[image_num], \n\u001b[0;32m---> 44\u001b[0;31m                                                          w1, w2, b1, b2, [1024, 10]).feed_forward_in_fc_layers()\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mbp_object\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mback_propagation_in_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc_layer_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_back_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-b99a7c76970c>\u001b[0m in \u001b[0;36mfeed_forward_in_fc_layers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shape ----- '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling_result_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mno_of_pool_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling_result_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mno_of_rows\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling_result_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mno_of_columns\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling_result_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layer_1\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mpooling_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_of_pool_results\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mno_of_rows\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mno_of_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "parameters, loss = train(X = train_x_reshaped, Y = train_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2],\n",
       "       [2, 2, 2],\n",
       "       [2, 2, 2]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = np.full((3, 3), 1)\n",
    "k = np.full((3, 3), 1)\n",
    "np.add(l, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2],\n",
       "       [2, 2, 2],\n",
       "       [2, 2, 2]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l + k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.5]\n",
      " [8.1]\n",
      " [8.7]\n",
      " [9.3]\n",
      " [9.9]]\n",
      "[[ 8.5]\n",
      " [ 9.1]\n",
      " [ 9.7]\n",
      " [10.3]\n",
      " [10.9]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "l = np.arange(30).reshape(6, 5)\n",
    "w = np.full((6, 1), 0.1)\n",
    "k = np.full((5, 1), 1)\n",
    "kk = np.dot(l.T, w)\n",
    "print(kk)\n",
    "kkk = (kk + k)\n",
    "print(kkk)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def s1(x):\n",
    "    #x = x.reshape(1, -1)\n",
    "    B = np.exp(x - max(x))\n",
    "    C = np.sum(B)\n",
    "    return B / C\n",
    "\n",
    "#s1(np.array([2345, 5678, 7654]))\n",
    "s1(np.array([-99864.9067806, -96041.73535487, -161880.11328138]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = ((np.uint16(((24 - 2) / 2) + 1),\n",
    "                                   np.uint16(((24 - 2) / 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
