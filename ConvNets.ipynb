{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validity_check(image, conv_filter, padding, stride):\n",
    "    \n",
    "    is_valid = True\n",
    "    image_shape = (np.shape(image))\n",
    "    filter_shape = (np.shape(conv_filter))\n",
    "    \n",
    "\n",
    "    if len(image_shape) != len(filter_shape) - 1:\n",
    "        print('Dimensions of both image and filter should be equal')\n",
    "        is_valid = False\n",
    "    \n",
    "    if len(image_shape) == 3 or len(filter_shape) > 3:\n",
    "        if image_shape[-1] != filter_shape[-1]:\n",
    "            print('Number of channels in both image and filter should be equal')\n",
    "            is_valid = False\n",
    "        \n",
    "    if filter_shape[1] != filter_shape[2]:\n",
    "        print(\"Filter should be of a square matrix\")\n",
    "        is_valid = False\n",
    "        \n",
    "        \n",
    "\n",
    "    if filter_shape[1] % 2 == 0:\n",
    "        print('dimensions of filter should be of odd dimensions not even')\n",
    "        is_valid = False\n",
    "    \n",
    "\n",
    "    '''\n",
    "    convolution_result is the array we obtain after running the filter all over the image\n",
    "    '''    \n",
    "    if is_valid:\n",
    "        '''one or more filters but only one channel (also for image)'''\n",
    "        if len(image_shape) == 2 and len(filter_shape) == 3:\n",
    "            \n",
    "            convolution_result = np.zeros((\n",
    "                            np.int16(((image_shape[0] + 2 * padding - filter_shape[1]) / stride) + 1),\n",
    "                            np.int16(((image_shape[1] + 2 * padding - filter_shape[2]) / stride) + 1)))\n",
    "            \n",
    "        '''one or more filters with more than one channel (also for image)'''\n",
    "        if len(image_shape) == 3 and len(filter_shape) == 4:\n",
    "            convolution_result = np.zeros((\n",
    "                            np.int16(((image_shape[0] + 2 * padding - filter_shape[1]) / stride) + 1),\n",
    "                            np.int16(((image_shape[1] + 2 * padding - filter_shape[2]) / stride) + 1),\n",
    "                            image_shape[3]))\n",
    "    else:\n",
    "        convolution_result = -1\n",
    "    \n",
    "    return [is_valid, convolution_result]\n",
    "\n",
    "\n",
    "def Relu(x):\n",
    "    indices = np.where(x < 0)\n",
    "    x[indices] = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The dimensions represent height, width and no_of_channels in the input image and filters\n",
    "'''\n",
    "\n",
    "\n",
    "class Conv_pool:\n",
    "    '''\n",
    "    self.conv_result, self.pooling_result and self.relu_result  are of shape (m, n, o, p)\n",
    "    m - length of  conv_result (or pooling_result or relu_result) - no of images\n",
    "    n - number of different conv_results (produced by each filter in the input) or pooling_results \n",
    "    0 - number of rows in each entry in  conv_result (or pooling_result)\n",
    "    p - number of columns in each entry in conv_result (or pooling_result)\n",
    "    '''\n",
    "    def __init__(self, image, conv_filter, conv_bias, padding, stride, pooling_filter_size, pooling_filter_stride):\n",
    "        self.curr_image         = image\n",
    "        self.conv_filter        = conv_filter\n",
    "        self.conv_bias          = conv_bias\n",
    "        self.conv_filter_stride = stride\n",
    "        self.pool_filter_size   = pooling_filter_size\n",
    "        self.pool_filter_stride = pooling_filter_stride\n",
    "        self.padding            = padding\n",
    "        self.conv_result        = np.array([])\n",
    "        self.relu_result        = np.array([])\n",
    "        self.pooling_result     = np.array([])\n",
    "            \n",
    "    \n",
    "    \n",
    "    #####################################################\n",
    "    \n",
    "    def apply_convolution_every_image(self, convolution_result):\n",
    "        image        = self.curr_image\n",
    "        conv_filter  = self.conv_filter\n",
    "        stride       = self.conv_filter_stride\n",
    "        image_shape  = np.shape(image)\n",
    "        filter_shape = np.shape(conv_filter)\n",
    "        \n",
    "        no_of_filters         = filter_shape[0]\n",
    "        convoluted_image_list = []\n",
    "        \n",
    "        '''this loop runs for all the different filters in the conv_filter'''\n",
    "        for filter_num in range(0, no_of_filters):\n",
    "            convoluted_image = np.array([])\n",
    "            filter_ = conv_filter[filter_num, :]\n",
    "    \n",
    "            '''if image has more than one channel'''\n",
    "            if len(image_shape) == 3 and image_shape[-1] == filter_shape[-1]:\n",
    "\n",
    "                convoluted_image = self.convolve_the_image_by_filter(image[:, :, 0], filter_[:, :, 0], \n",
    "                                                                   convolution_result)\n",
    "                for channel in range(1, filter_shape[-1]):\n",
    "                    convoluted_image = convoluted_image + self.convolve_the_image_by_filter(image[:, :, channel], \n",
    "                                                                                             filter_[:, :, channel],\n",
    "                                                                                                 convolution_result)\n",
    "            '''if image has only one channel'''\n",
    "            if len(image_shape) == 2:\n",
    "                \n",
    "                convoluted_image = self.convolve_the_image_by_filter(image, filter_, convolution_result)\n",
    "            '''here, you used copy.copy() so as to refrain the convoluted_image_list getting over-written\n",
    "            by the new entries into the list'''\n",
    "            \n",
    "            convoluted_image = np.add(convoluted_image, self.conv_bias)\n",
    "            convoluted_image_list.append(copy.copy(convoluted_image))\n",
    "            \n",
    "        self.conv_result = np.array(convoluted_image_list)\n",
    "            \n",
    "    \n",
    "    \n",
    "    #########################################################\n",
    "    '''\n",
    "    when supplied with both image and filter, perform either convolution or pooling\n",
    "    '''\n",
    "    def apply_conv_or_pooling_on_data(self, image, filter_size, result, \n",
    "                                       stride_length, is_pooling, conv_filter = None):\n",
    "        \n",
    "        row_count = 0\n",
    "        column_count = 0\n",
    "\n",
    "        image_shape = np.shape(image)[1]\n",
    "        for row in range(0, image_shape, stride_length):\n",
    "            if row + filter_size <= image_shape:\n",
    "                column_count = 0\n",
    "                for column in range(0, image_shape, stride_length):\n",
    "\n",
    "                    if column + filter_size <= image_shape:\n",
    "                        \n",
    "                        '''present active region is the region in the image which will be multiplied\n",
    "                            by the filter'''\n",
    "                        if not is_pooling:\n",
    "                            \n",
    "                            present_active_region           = image[row : (row + filter_size), \n",
    "                                                                          column : (column + filter_size)]\n",
    "                            image_area_product_filter       = present_active_region * conv_filter\n",
    "                            sum_of_all_elements             = np.sum(image_area_product_filter)\n",
    "                            result[row_count, column_count] = sum_of_all_elements\n",
    "                        \n",
    "                        if is_pooling:\n",
    "                            \n",
    "                            active_region       = image[row : (row + filter_size), \n",
    "                                                                    column : (column + filter_size)] \n",
    "                            result[row_count, column_count] = np.max(active_region)\n",
    "\n",
    "                            \n",
    "                        column_count = column_count + 1\n",
    "            row_count = row_count + 1\n",
    "        \n",
    "        return result\n",
    "        \n",
    "        \n",
    "           \n",
    "    ######################################################\n",
    "    \n",
    "    def convolve_the_image_by_filter(self, image, conv_filter, convolution_result):\n",
    "        \n",
    "        stride      = self.conv_filter_stride\n",
    "        image_shape = np.shape(image)    \n",
    "        filter_size = np.shape(conv_filter)[0]\n",
    "        \n",
    "        result = self.apply_conv_or_pooling_on_data(image, filter_size, \n",
    "                                                    convolution_result, stride, False, conv_filter)\n",
    "        return result\n",
    "\n",
    "    \n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    def relu_on_convolution_result(self):\n",
    "        convolution_result_          = self.conv_result\n",
    "        conv_result_shape            = np.shape(convolution_result_)\n",
    "        no_of_times_image_convoluted = conv_result_shape[0]\n",
    "        \n",
    "        \n",
    "            \n",
    "        relu_result_list = []\n",
    "\n",
    "        for result_num in range(0, no_of_times_image_convoluted):\n",
    "\n",
    "            current_convoluted_image = convolution_result_[result_num, :]\n",
    "            indices = np.where(current_convoluted_image <= 0)\n",
    "            current_convoluted_image[indices] = 0\n",
    "            relu_result_list.append(current_convoluted_image)\n",
    "\n",
    "        self.relu_result = np.array(relu_result_list)\n",
    "\n",
    "        \n",
    "    ######################################################\n",
    "    \n",
    "    '''max pooling'''    \n",
    "    def pooling_on_relu_result(self):\n",
    "        relu_result = self.relu_result\n",
    "        pool_size   = self.pool_filter_size\n",
    "        stride      = self.pool_filter_stride\n",
    "        \n",
    "\n",
    "        relu_result_shape            = np.shape(relu_result)\n",
    "        \n",
    "        no_of_relu_results_per_image = np.shape(relu_result)[0]\n",
    "        relu_result_shape_each_image = np.shape(relu_result)[1]\n",
    "\n",
    "        pooling_result_list = []\n",
    "        \n",
    "        \n",
    "    \n",
    "        for relu_result_num in range(0, no_of_relu_results_per_image):\n",
    "\n",
    "            curr_relu = relu_result[relu_result_num, :]\n",
    "\n",
    "            pooling_result   = np.zeros((np.uint16(((relu_result_shape_each_image - pool_size) / stride) + 1),\n",
    "                                   np.uint16(((relu_result_shape_each_image - pool_size) / stride) + 1)))\n",
    "\n",
    "            result = self.apply_conv_or_pooling_on_data(image = curr_relu, filter_size = pool_size, \n",
    "                                                        result = pooling_result, stride_length = stride, \n",
    "                                                        is_pooling = True)\n",
    "            pooling_result_list.append(result)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        self.pooling_result = np.array(pooling_result_list)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def pad_the_image(self):\n",
    "        pad_img = np.array()\n",
    "        if self.conv_filter.shape[1] == 3:\n",
    "            pad_img = np.zeros((30, 30))\n",
    "        \n",
    "        if self.conv_filter.shape[1] == 5:\n",
    "            pad_img = np.zeros((32, 32))\n",
    "            \n",
    "        pad_img[1 : self.curr_image.shape[1] + 1, 1 : self.curr_image.shape[1] + 1]  = self.curr_image\n",
    "        self.curr_image = pad_img\n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    def CNN(self):\n",
    "        \n",
    "        if self.padding:\n",
    "            self.pad_the_image()\n",
    "            \n",
    "        validity_convolution_result = validity_check(self.curr_image, self.conv_filter, \n",
    "                                                     self.padding, self.conv_filter_stride)\n",
    "        if validity_convolution_result[0]:\n",
    "            convolution_result = validity_convolution_result[1]\n",
    "            self.apply_convolution_every_image(convolution_result)\n",
    "            self.relu_on_convolution_result()\n",
    "            self.pooling_on_relu_result()\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu(x):\n",
    "    indices = np.where(x <= 0)\n",
    "    x[indices] = 0\n",
    "    return x\n",
    "    \n",
    "def softmax(x):\n",
    "    x = x.reshape(1, -1)\n",
    "    B = np.exp(x - max(x))\n",
    "    C = np.sum(B)\n",
    "    return B / C\n",
    "\n",
    "\n",
    "\n",
    "def cross_entropy(output, labels):\n",
    "    return -np.sum(labels * np.log(output))\n",
    "\n",
    "\n",
    "\n",
    "class fully_connected_layers_in_CNN:\n",
    "    \n",
    "    def __init__(self, conv_pool_object, labels, weights_1, weights_2, bias_1, bias_2, no_of_neurons):\n",
    "        self.conv_pool_result = conv_pool_object\n",
    "        self.pooling_result = conv_pool_object.pooling_result\n",
    "        self.labels = labels\n",
    "        self.pooling_result_shape = np.shape(self.pooling_result)\n",
    "        self.neurons = no_of_neurons\n",
    "    \n",
    "        self.weights_1 = weights_1\n",
    "        self.weights_2 = weights_2\n",
    "        self.bias_1    = bias_1\n",
    "        self.bias_2    = bias_2\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ##########################################################\n",
    "    \n",
    "    def feed_forward_in_fc_layers(self):\n",
    "            \n",
    "        pooling_result     = self.pooling_result\n",
    "        no_of_neurons      = self.neurons\n",
    "\n",
    "        no_of_pool_results = self.pooling_result_shape[0]\n",
    "        no_of_rows         = self.pooling_result_shape[1]\n",
    "        no_of_columns      = self.pooling_result_shape[2]\n",
    "        self.fc_layer_1    = pooling_result.reshape(((no_of_pool_results * no_of_rows * no_of_columns), 1))\n",
    "        \n",
    "\n",
    "        self.z_1             = np.add(np.dot(self.weights_1.T, self.fc_layer_1), self.bias_1)\n",
    "        self.fc_layer_2      = Relu(self.z_1)\n",
    "        \n",
    "\n",
    "        self.z_2             = np.add(np.dot(self.weights_2.T, self.fc_layer_2), self.bias_2)\n",
    "        self.predicted_probs = softmax(self.z_2)\n",
    "          \n",
    "        self.loss = cross_entropy(self.predicted_probs, self.labels)\n",
    "        self.diff_btw_pred_and_actual_labels = self.predicted_probs - self.labels\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class back_propagation_in_CNN:\n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def __init__(self, fc_layer_object):\n",
    "        self.fc_layer_object = fc_layer_object\n",
    "        self.conv_pool_result = fc_layer_object.conv_pool_result\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def get_the_index(self, conv_sub_array):\n",
    "        position_of_max_element = np.nanargmax(conv_sub_array)\n",
    "        index_of_max_element = np.unravel_index(position_of_max_element, conv_sub_array.shape)\n",
    "        return index_of_max_element\n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def backpropagation_wrt_pooling_result(self, derivative_pool_result):\n",
    "        \n",
    "        conv_result        = self.conv_pool_result.conv_result\n",
    "        pool_filter_size   = self.conv_pool_result.pool_filter_size\n",
    "        pool_filter_stride = self.conv_pool_result.pool_filter_stride\n",
    "        \n",
    "        no_of_convolved_images, no_of_rows, no_of_columns = np.shape(conv_result)\n",
    "        _, pool_row_length, _ = np.shape(derivative_pool_result)\n",
    "        output = np.zeros(np.shape(conv_result))\n",
    "    \n",
    "        row_count = 0\n",
    "        column_count = 0\n",
    "        for image_num in range(0, no_of_convolved_images):\n",
    "            current_image = conv_result[image_num, :]\n",
    "            row_count = 0\n",
    "            for row in range(0, no_of_rows, pool_filter_stride):\n",
    "                if row + pool_filter_size <= no_of_rows:\n",
    "                    column_count = 0\n",
    "                    for column in range(0, no_of_columns, pool_filter_stride):\n",
    "                        if column + pool_filter_size <= no_of_columns:\n",
    "                            image_sub_array = current_image[row : row + pool_filter_size, column : column + pool_filter_size]\n",
    "                            '''index of the max element in the original conv_image (in the area covered by pool filter)'''\n",
    "                            (i, j) = self.get_the_index(image_sub_array)\n",
    "                            if row_count <= pool_row_length:\n",
    "                                output[image_num, row + i, column + j] = derivative_pool_result[image_num, \n",
    "                                                                                            row_count, column_count]\n",
    "                            column_count = column_count + 1\n",
    "                \n",
    "                row_count = row_count + 1\n",
    "            \n",
    "        return output\n",
    "                              \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def backpropagation_wrt_convolution_layer(self, der_conv_prev):\n",
    "                \n",
    "        conv_curr_image      = self.conv_pool_result.curr_image\n",
    "        conv_image_curr_list = [conv_curr_image]\n",
    "        conv_image_curr      = np.array(conv_image_curr_list)\n",
    "        conv_filter          = self.conv_pool_result.conv_filter\n",
    "        conv_bias            = self.conv_pool_result.conv_bias\n",
    "        filter_stride        = self.conv_pool_result.conv_filter_stride\n",
    "        no_of_filters, flt_size, no_of_columns_f = np.shape(conv_filter)\n",
    "        \n",
    "        len_of_shape_of_curr_image  = len(np.shape(conv_image_curr))\n",
    "        _,no_of_rows, no_of_columns = np.shape(conv_image_curr)\n",
    "\n",
    "        \n",
    "        der_wrt_filter = np.zeros(np.shape(conv_filter))\n",
    "        der_wrt_bias   = np.zeros(np.shape(conv_bias))\n",
    "        dconv_result   = np.zeros(np.shape(conv_image_curr))\n",
    "\n",
    "        \n",
    "        r_count = 0\n",
    "        c_count = 0\n",
    "        \n",
    "        for filter_num in range(0, no_of_filters):\n",
    "            r_count = 0\n",
    "            for r in range(0, no_of_rows, filter_stride):\n",
    "                if r + flt_size <= no_of_rows:\n",
    "                    c_count = 0\n",
    "                    for c in range(0, no_of_columns, filter_stride):\n",
    "                        if c + flt_size <= no_of_columns:\n",
    "                            '''update the filter'''\n",
    "                            der_conv_prev_ = der_conv_prev[filter_num]\n",
    "#                             der_wrt_filter[filter_num] += der_conv_prev[filter_num, r_count, c_count] * conv_image_curr[:, \n",
    "#                                                                                                          r : r + flt_size,\n",
    "#                                                                                                          c : c + flt_size]\n",
    "                            der_wrt_filter[filter_num] += der_conv_prev_[r_count, c_count] * conv_curr_image[r : r + flt_size,\n",
    "                                                                                                             c : c + flt_size]\n",
    "                            \n",
    "                            dconv_result[:, r : r + flt_size, c : c + flt_size] += der_conv_prev[filter_num, r_count, c_count] * conv_filter[filter_num, :]\n",
    "                            \n",
    "                            c_count = c_count + 1\n",
    "                r_count = r_count + 1\n",
    "        \n",
    "#             der_wrt_bias[filter_num] = np.sum(der_conv_prev[filter_num])\n",
    "            der_wrt_bias = (der_conv_prev[filter_num])\n",
    "        \n",
    "        \n",
    "        return dconv_result, der_wrt_filter, der_wrt_bias\n",
    "                                \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def start_back_propagation(self):\n",
    "        \n",
    "        fc_layer_object = self.fc_layer_object\n",
    "        fc_layer_1      = fc_layer_object.fc_layer_1\n",
    "        \n",
    "        self.der_wrt_weights_2  = np.dot(fc_layer_object.z_1, fc_layer_object.diff_btw_pred_and_actual_labels)\n",
    "        \n",
    "        temporary_result = np.dot(fc_layer_object.weights_2,  \n",
    "                                  fc_layer_object.diff_btw_pred_and_actual_labels.T)\n",
    "        \n",
    "        self.der_wrt_weights_1 = np.dot(fc_layer_object.fc_layer_1, temporary_result.T)\n",
    "        \n",
    "        self.der_wrt_bias_2    = np.sum(fc_layer_object.diff_btw_pred_and_actual_labels, axis = 1).T\n",
    "        self.der_wrt_bias_1    = np.sum(temporary_result, axis = 1).reshape(fc_layer_object.bias_1.shape)\n",
    "        \n",
    "        der_fc_layer_1 = np.dot(fc_layer_object.weights_1, temporary_result)\n",
    "        reshaped_dfc_layer_1 = der_fc_layer_1.reshape(fc_layer_object.pooling_result_shape)\n",
    "        \n",
    "\n",
    "        '''back propagating through max-pooling layer (updating only those neurons with highest value)'''\n",
    "        der_pool_layer = self.backpropagation_wrt_pooling_result(reshaped_dfc_layer_1)\n",
    "        \n",
    "        '''back propagating through Relu layer'''\n",
    "        der_pool_layer[fc_layer_object.conv_pool_result.conv_result <= 0] = 0\n",
    "        der_image, der_filter, der_conv_bias = self.backpropagation_wrt_convolution_layer(der_pool_layer)\n",
    "        \n",
    "        self.return_result = [der_filter, der_conv_bias]\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########################################################\n",
    "def read_data(directory_path, is_train_data):\n",
    "    if is_train_data:\n",
    "        mnsit_data = pd.read_csv(directory_path, header=None, low_memory = False)\n",
    "        mnsit_data.drop(0, axis = 0, inplace = True)\n",
    "        train_Y    = mnsit_data[0].astype(np.float32)\n",
    "        mnsit_data.drop(0, axis = 1, inplace = True)\n",
    "        mnsit_data = mnsit_data.astype(np.float32)\n",
    "\n",
    "        return mnsit_data, train_Y\n",
    "    \n",
    "    else:\n",
    "        mnsit_test = pd.read_csv(directory_path, header = None, low_memory = False)\n",
    "        mnsit_test.drop(0, axis = 0, inplace = True)\n",
    "        mnsit_test = mnsit_test.astype(np.float32)\n",
    "        \n",
    "        return mnsit_test\n",
    "    \n",
    "    \n",
    "    \n",
    "##########################################################\n",
    "def split_the_train_data(train_X, train_Y):\n",
    "    train_x, train_y, test_x, test_y = train_test_split(train_X, train_Y, test_size = 0.2, \n",
    "                                                        random_state = 42)\n",
    "    \n",
    "    return [[train_x, test_x], [train_y, test_y]]\n",
    "    \n",
    "##########################################################\n",
    "def convert_labels_to_one_hot_encoding_format(train_y, test_y):\n",
    "    one_hot_encoder = OneHotEncoder(categories = 'auto')\n",
    "    train_y_encoded = one_hot_encoder.fit_transform(train_y).toarray()\n",
    "    test_y_encoded  = one_hot_encoder.fit_transform(test_y).toarray()\n",
    "    return train_y_encoded.astype(np.float32), test_y_encoded.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "def convert_input_to_image_format(data):\n",
    "    output = []\n",
    "    no_of_rows = np.shape(data)[0]\n",
    "    for row_num in range(0, no_of_rows):\n",
    "        output.append(data.iloc[row_num].values.reshape(28, 28))\n",
    "    \n",
    "    return np.array(output).astype(np.float32)\n",
    "    \n",
    "\n",
    "\n",
    "##########################################################\n",
    "def standardize_the_data(train_data, test_data):\n",
    "    scaler = StandardScaler().fit(train_data)\n",
    "    train_data_scaled = scaler.transform(train_data)\n",
    "    test_data_scaled  = scaler.transform(test_data)\n",
    "    return pd.DataFrame(train_data_scaled, dtype = np.float32), pd.DataFrame(test_data_scaled, dtype = np.float32)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow-session/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/envs/tensorflow-session/lib/python3.6/site-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
      "/anaconda3/envs/tensorflow-session/lib/python3.6/site-packages/ipykernel_launcher.py:55: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "train_X, train_Y = read_data('/Users/vijay/Downloads/digit-recognizer/train.csv', True)\n",
    "test_X           = read_data('/Users/vijay/Downloads/digit-recognizer/test.csv', False)\n",
    "\n",
    "train_test_data  = split_the_train_data(train_X, train_Y)\n",
    "train_x, train_y = train_test_data[0]\n",
    "test_x, test_y   = train_test_data[1]\n",
    "\n",
    "train_x_standardized, test_x_standardized = standardize_the_data(train_x, test_x)\n",
    "train_x_reshaped = convert_input_to_image_format(train_x_standardized)\n",
    "test_x_reshaped   = convert_input_to_image_format(test_x_standardized)\n",
    "\n",
    "train_y_encoded, test_y_encoded = convert_labels_to_one_hot_encoding_format(train_y.values.reshape(-1, 1), \n",
    "                                                                           test_y.values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "del(train_x)\n",
    "del(test_x)\n",
    "del(train_y)\n",
    "del(test_y)\n",
    "del(train_x_standardized)\n",
    "del(test_x_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_filters_for_convolution(filter_size, no_of_filters, no_of_channels):\n",
    "    \n",
    "    if no_of_channels == 1:\n",
    "        conv_filters = np.zeros((no_of_filters, filter_size, filter_size))\n",
    "        for i in range(0, no_of_filters):\n",
    "            \n",
    "            filter_ = np.random.random((filter_size, filter_size))\n",
    "            conv_filters[i, :, :] = filter_\n",
    "            \n",
    "        return conv_filters\n",
    "    else:\n",
    "        conv_filters = np.zeros((no_of_filters, filter_size, filter_size, no_of_channels))\n",
    "        \n",
    "        for i in range(0, no_of_filters):\n",
    "            filter_ = np.random.random((filter_size, filter_size, no_of_channels))\n",
    "            conv_filters[i, :, :, :] = filter_\n",
    "\n",
    "        return conv_filters\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "def get_weights_for_fc_layers(no_of_filters, image_size, conv_f_size, \n",
    "                                 pool_size, conv_f_stride, pool_stride, no_of_convolutions, padding, no_of_neurons):\n",
    "    for num in range(0, no_of_convolutions):\n",
    "        \n",
    "        conv_size  = np.int16(((image_size + 2 * padding - conv_f_size) / conv_f_stride) + 1)\n",
    "        pool_size  = np.uint16(((conv_size - pool_size) / pool_stride) + 1)\n",
    "        image_size = pool_size\n",
    "    \n",
    "    \n",
    "    weights_1 = np.random.random(((no_of_filters * image_size * image_size), no_of_neurons[0]))\n",
    "    weights_2 = np.random.random((no_of_neurons[0], no_of_neurons[1]))\n",
    "    \n",
    "    return weights_1, weights_2\n",
    "    \n",
    "\n",
    "def get_biases_for_convolution(bias_size):\n",
    "    conv_bias = np.full((bias_size, bias_size), 0.1)\n",
    "    return conv_bias\n",
    "    \n",
    "\n",
    "def get_biases_for_fc_layers():\n",
    "    bias_1 = np.random.random((1024, 1))\n",
    "    bias_2 = np.random.random((10, 1))\n",
    "    \n",
    "    return bias_1, bias_2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 336\n",
    "\n",
    "def update_parameters_for_each_batch(train_x, train_y, beta1, beta2, learning_rate, parameters, pooling_filter_size,\n",
    "                                        pooling_filter_stride, padding, stride, loss):\n",
    "    \n",
    "    cf, cb, w1, w2, b1, b2 = parameters\n",
    "    conv_filter_shape = np.shape(cf)\n",
    "    conv_bias_shape   = np.shape(cb)\n",
    "    weights_1_shape   = np.shape(w1)\n",
    "    weights_2_shape   = np.shape(w2)\n",
    "    bias_1_shape      = np.shape(b1)\n",
    "    bias_2_shape      = np.shape(b2)\n",
    "    \n",
    "    \n",
    "    loss_        = 0\n",
    "    conv_filter_ = np.zeros(conv_filter_shape)\n",
    "    conv_bias_   = np.zeros(conv_bias_shape) \n",
    "    weights_1_   = np.zeros(weights_1_shape)\n",
    "    weights_2_   = np.zeros(weights_2_shape)\n",
    "    bias_1_      = np.zeros(bias_1_shape)\n",
    "    bias_2_      = np.zeros(bias_2_shape)\n",
    "\n",
    "    v_cf   = np.zeros(conv_filter_shape)\n",
    "    v_w_1  = np.zeros(weights_1_shape)\n",
    "    v_w_2  = np.zeros(weights_2_shape)\n",
    "    v_cb   = np.zeros(conv_bias_shape)\n",
    "    v_w1_b = np.zeros(bias_1_shape)\n",
    "    v_w2_b = np.zeros(bias_2_shape)\n",
    "\n",
    "    u_cf   = np.zeros(conv_filter_shape)\n",
    "    u_w_1  = np.zeros(weights_1_shape)\n",
    "    u_w_2  = np.zeros(weights_2_shape)\n",
    "    u_cb   = np.zeros(conv_bias_shape)\n",
    "    u_w1_b = np.zeros(bias_1_shape)\n",
    "    u_w2_b = np.zeros(bias_2_shape)\n",
    "\n",
    "\n",
    "\n",
    "    for image_num in range(0, batch_size):\n",
    "\n",
    "        conv_pool_object = Conv_pool(train_x[image_num], cf, cb, padding = 0, stride = 1, \n",
    "                                                    pooling_filter_size = 2, pooling_filter_stride = 2)\n",
    "        conv_pool_object.CNN()\n",
    "        \n",
    "        fc_layer_object  = fully_connected_layers_in_CNN(conv_pool_object, train_y[image_num], \n",
    "                                                         w1, w2, b1, b2, [1024, 10])\n",
    "        fc_layer_object.feed_forward_in_fc_layers()\n",
    "        \n",
    "        bp_object        = back_propagation_in_CNN(fc_layer_object)\n",
    "        bp_object.start_back_propagation()\n",
    "\n",
    "\n",
    "        d_conv_filter, d_conv_bias  = bp_object.return_result\n",
    "        d_wt_1, d_wt_2              = bp_object.der_wrt_weights_1, bp_object.der_wrt_weights_2, \n",
    "        d_bias_1, d_bias_2          = bp_object.der_wrt_bias_1, bp_object.der_wrt_bias_2\n",
    "        \n",
    "        \n",
    "        conv_filter_ += d_conv_filter\n",
    "        conv_bias_   += d_conv_bias\n",
    "        weights_1_   += d_wt_1\n",
    "        weights_2_   += d_wt_2\n",
    "        bias_1_      += d_bias_1\n",
    "        bias_2_      += d_bias_2\n",
    "        loss_        += fc_layer_object.loss\n",
    "            \n",
    "            \n",
    "            \n",
    "        v_cf = beta1 * v_cf + (1 - beta1) * (conv_filter_ / batch_size) \n",
    "        u_cf = beta2 * u_cf + (1 - beta2) * (conv_filter_ / batch_size) ** 2\n",
    "        cf  -= learning_rate * v_cf / np.sqrt(u_cf + 1e-7)\n",
    "\n",
    "        v_cb = beta1 * v_cb + (1 - beta1) * conv_bias_ / batch_size\n",
    "        u_cb = beta2 * u_cb + (1 - beta2) * (conv_bias_ / batch_size) ** 2\n",
    "        cb  -= learning_rate * v_cb / np.sqrt(u_cb + 1e-7)\n",
    "\n",
    "        v_w_1 = beta1 * v_w_1 + (1 - beta1) * weights_1_ / batch_size\n",
    "        u_w_1 = beta2 * u_w_1 + (1 - beta2) * (weights_1_ / batch_size) ** 2\n",
    "        w1   -= learning_rate * v_w_1/np.sqrt(u_w_1 + 1e-7)\n",
    "\n",
    "        v_w_2 = beta1 * v_w_2 + (1 - beta1) * weights_2_ / batch_size\n",
    "        u_w_2 = beta2 * u_w_2 + (1 - beta2) * (weights_2_ / batch_size) ** 2\n",
    "        w2   -= learning_rate * v_w_2/np.sqrt(u_w_2 + 1e-7)\n",
    "\n",
    "\n",
    "        v_w1_b = beta1 * v_w1_b + (1 - beta1) * bias_1_ / batch_size\n",
    "        u_w1_b = beta2 * u_w1_b + (1 - beta2) * (bias_1_ / batch_size) ** 2\n",
    "        b1    -= learning_rate * v_w1_b/np.sqrt(u_w1_b+1e-7)\n",
    "\n",
    "        v_w2_b = beta1 * v_w2_b + (1 - beta1) * bias_2_ / batch_size\n",
    "        u_w2_b = beta2 * u_w2_b + (1 - beta2) * (bias_2_ / batch_size) ** 2\n",
    "        b2    -= learning_rate * v_w2_b/np.sqrt(u_w2_b+1e-7)\n",
    "        \n",
    "        loss_ = loss_ / batch_size\n",
    "        loss.append(loss_)\n",
    "        parameters = [cf, cb, w1, w2, b1, b2] \n",
    "        \n",
    "        \n",
    "        return parameters, loss\n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "def train(X, Y, img_size = 28, no_of_channels = 1, lr = 0.01, beta1 = 0.95, beta2 =0.99, \n",
    "                                    no_of_conv_filter = 8, batch_size = 50, no_of_epochs = 1000):\n",
    "    \n",
    "    conv_filter = get_filters_for_convolution(filter_size = 3, no_of_filters = 32, no_of_channels = 1)\n",
    "    conv_bias   = get_biases_for_convolution(26)\n",
    "\n",
    "    weights_1, weights_2 = get_weights_for_fc_layers(32, 28, 3, 2, 1, 2, 1, 0, [1024, 10])\n",
    "    bias_1, bias_2       = get_biases_for_fc_layers()\n",
    "    \n",
    "    parameters = [conv_filter, conv_bias, weights_1, weights_2, bias_1, bias_2]\n",
    "    loss = []\n",
    "    no_of_rows = len(X)\n",
    "    \n",
    "    \n",
    "    for epoch in range(0, no_of_epochs):\n",
    "        X, Y = shuffle(X, Y)\n",
    "        \n",
    "        for row in range(0, no_of_rows, batch_size):\n",
    "                train_x = X[row : row + batch_size, :]\n",
    "                train_y  = Y[row : row + batch_size, :]\n",
    "                parameters, loss = update_parameters_for_each_batch(train_x, train_y, beta1, beta2, lr, parameters, \n",
    "                                                                     2, 2, 0, 1, loss)\n",
    "    \n",
    "        \n",
    "    return parameters, loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters, loss = train(X = train_x_reshaped, Y = train_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08939119, 0.10935725, 0.09175704, 0.12985655, 0.07795867,\n",
       "        0.09973649, 0.09186158, 0.09481164, 0.1       , 0.1       ,\n",
       "        0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "        0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "        0.1       , 0.09288463, 0.1147374 , 0.07857222, 0.09502389,\n",
       "        0.08639448],\n",
       "       [0.09688728, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "        0.1       , 0.1       , 0.1       , 0.1       , 0.10481582,\n",
       "        0.1       , 0.10200274, 0.10182156, 0.1       , 0.1       ,\n",
       "        0.09034366, 0.1       , 0.09531761, 0.09236595, 0.10427711,\n",
       "        0.09116316, 0.1       , 0.0951832 , 0.1       , 0.1       ,\n",
       "        0.11653055],\n",
       "       [0.08166085, 0.09284706, 0.06549339, 0.09507385, 0.1       ,\n",
       "        0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "        0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "        0.0950499 , 0.1       , 0.09510287, 0.09504986, 0.1       ,\n",
       "        0.1       , 0.1       , 0.09522571, 0.1       , 0.1       ,\n",
       "        0.11012284],\n",
       "       [0.0972072 , 0.1       , 0.10580754, 0.10499049, 0.1       ,\n",
       "        0.10497975, 0.10498506, 0.11895676, 0.10987546, 0.10878352,\n",
       "        0.10275189, 0.1068818 , 0.0982797 , 0.11151342, 0.09855159,\n",
       "        0.09397814, 0.11833074, 0.08939416, 0.10632862, 0.08566288,\n",
       "        0.10498547, 0.09508947, 0.09507127, 0.09510481, 0.09009384,\n",
       "        0.1       ],\n",
       "       [0.08225458, 0.1       , 0.1       , 0.10497775, 0.10498696,\n",
       "        0.1       , 0.10498644, 0.09576504, 0.1       , 0.10549856,\n",
       "        0.10081775, 0.1017675 , 0.09999925, 0.10468096, 0.10955565,\n",
       "        0.09023126, 0.09744797, 0.10812932, 0.09383295, 0.09573123,\n",
       "        0.09511469, 0.1       , 0.09537115, 0.1       , 0.09503356,\n",
       "        0.1       ],\n",
       "       [0.10551755, 0.09518567, 0.1       , 0.10001484, 0.1       ,\n",
       "        0.1002921 , 0.1010992 , 0.10038249, 0.1192849 , 0.085169  ,\n",
       "        0.10862805, 0.11007087, 0.10461517, 0.10917077, 0.10672972,\n",
       "        0.09035156, 0.10843247, 0.10211972, 0.11045831, 0.0968531 ,\n",
       "        0.09269915, 0.09499932, 0.1073526 , 0.09512665, 0.09518202,\n",
       "        0.1       ],\n",
       "       [0.11891441, 0.1       , 0.1       , 0.09600808, 0.1       ,\n",
       "        0.1       , 0.10398703, 0.10498844, 0.11692356, 0.09906517,\n",
       "        0.11220647, 0.10997558, 0.11515939, 0.1       , 0.11055164,\n",
       "        0.09844847, 0.08680208, 0.09679393, 0.10045309, 0.09635212,\n",
       "        0.08057979, 0.09501365, 0.09496884, 0.0973552 , 0.09031334,\n",
       "        0.1       ],\n",
       "       [0.1       , 0.09503445, 0.1       , 0.10493795, 0.10487274,\n",
       "        0.10654185, 0.10492984, 0.09013972, 0.09529534, 0.11963851,\n",
       "        0.09014651, 0.10181183, 0.1075739 , 0.08967682, 0.09115491,\n",
       "        0.114735  , 0.09662897, 0.10059873, 0.10040552, 0.09881593,\n",
       "        0.12052716, 0.10034729, 0.11110908, 0.1       , 0.10000465,\n",
       "        0.1       ],\n",
       "       [0.1       , 0.09508147, 0.10487818, 0.09503467, 0.09813291,\n",
       "        0.10497354, 0.10835677, 0.09014024, 0.09531557, 0.10010332,\n",
       "        0.09801587, 0.09997424, 0.11253688, 0.09533119, 0.08696524,\n",
       "        0.09990798, 0.10964892, 0.10500818, 0.09972401, 0.1210647 ,\n",
       "        0.09558964, 0.09885766, 0.100066  , 0.1       , 0.09503586,\n",
       "        0.1       ],\n",
       "       [0.1       , 0.1       , 0.1       , 0.10991202, 0.1       ,\n",
       "        0.10655493, 0.1       , 0.09455589, 0.09290235, 0.11515593,\n",
       "        0.10485398, 0.09267447, 0.10353211, 0.07875832, 0.08632455,\n",
       "        0.10763672, 0.10233908, 0.1043709 , 0.10083366, 0.08540334,\n",
       "        0.10465255, 0.10747092, 0.11313753, 0.1       , 0.10027763,\n",
       "        0.1       ],\n",
       "       [0.1       , 0.1       , 0.1       , 0.10489301, 0.1       ,\n",
       "        0.10003448, 0.10996364, 0.08630618, 0.09127841, 0.1141239 ,\n",
       "        0.09506216, 0.10048925, 0.09378916, 0.10490654, 0.08600576,\n",
       "        0.10823879, 0.09904546, 0.10487551, 0.08071644, 0.10406699,\n",
       "        0.10032165, 0.10498431, 0.09526124, 0.1       , 0.10008235,\n",
       "        0.1       ],\n",
       "       [0.10511543, 0.1       , 0.1       , 0.11266078, 0.10498567,\n",
       "        0.09583778, 0.11141928, 0.10044001, 0.10166385, 0.09142414,\n",
       "        0.09018237, 0.10336845, 0.11018028, 0.08527618, 0.09982287,\n",
       "        0.10119239, 0.08909402, 0.08383595, 0.10909472, 0.10564494,\n",
       "        0.08746449, 0.10462918, 0.10752362, 0.1       , 0.1       ,\n",
       "        0.1       ],\n",
       "       [0.10559161, 0.1       , 0.1       , 0.09542854, 0.10497795,\n",
       "        0.09837208, 0.11278895, 0.10617911, 0.10088844, 0.09110952,\n",
       "        0.09057147, 0.12013781, 0.09199858, 0.0924275 , 0.10026086,\n",
       "        0.08560834, 0.10010148, 0.08541556, 0.09117295, 0.10908405,\n",
       "        0.09456162, 0.1000265 , 0.11229896, 0.1       , 0.10036493,\n",
       "        0.1       ],\n",
       "       [0.06867109, 0.1       , 0.1       , 0.11054579, 0.1       ,\n",
       "        0.10888697, 0.10013534, 0.08232169, 0.09510198, 0.10521278,\n",
       "        0.10004898, 0.10112418, 0.09572768, 0.11960861, 0.11065077,\n",
       "        0.08907852, 0.09877096, 0.10031948, 0.08729448, 0.10056357,\n",
       "        0.09839767, 0.10975567, 0.10753043, 0.1       , 0.1       ,\n",
       "        0.1       ],\n",
       "       [0.087705  , 0.1       , 0.1       , 0.10685006, 0.10498656,\n",
       "        0.09589419, 0.10557884, 0.08833239, 0.08812761, 0.09503271,\n",
       "        0.09489788, 0.0905318 , 0.10982336, 0.1       , 0.09510559,\n",
       "        0.11781457, 0.0940621 , 0.1003041 , 0.10501424, 0.10095927,\n",
       "        0.1088718 , 0.1006176 , 0.11166617, 0.1       , 0.10492203,\n",
       "        0.1       ],\n",
       "       [0.11391292, 0.1       , 0.1       , 0.10420463, 0.10991957,\n",
       "        0.09477305, 0.1006544 , 0.09651862, 0.09985049, 0.11374612,\n",
       "        0.1096739 , 0.09513361, 0.08109747, 0.08515191, 0.10186282,\n",
       "        0.08976944, 0.09417941, 0.09537578, 0.09997079, 0.10820886,\n",
       "        0.08795914, 0.1       , 0.10254451, 0.1       , 0.1       ,\n",
       "        0.1       ],\n",
       "       [0.09835479, 0.1       , 0.1       , 0.09109086, 0.1       ,\n",
       "        0.10506432, 0.11417211, 0.10989314, 0.09551425, 0.10983266,\n",
       "        0.11485063, 0.09506566, 0.07179054, 0.09511076, 0.07888994,\n",
       "        0.09020056, 0.08066398, 0.09021702, 0.11117023, 0.10462663,\n",
       "        0.10584333, 0.1       , 0.10988668, 0.1       , 0.1       ,\n",
       "        0.1       ],\n",
       "       [0.1       , 0.09512841, 0.1       , 0.10378998, 0.10061219,\n",
       "        0.09340073, 0.10231029, 0.09705985, 0.08525876, 0.10040024,\n",
       "        0.10727225, 0.09175447, 0.10619892, 0.10394711, 0.10519692,\n",
       "        0.10642193, 0.11064101, 0.09929759, 0.0950369 , 0.11943332,\n",
       "        0.1002466 , 0.10329433, 0.104933  , 0.1       , 0.1       ,\n",
       "        0.1       ],\n",
       "       [0.08526021, 0.1       , 0.1       , 0.11505383, 0.10016658,\n",
       "        0.09009451, 0.09310488, 0.10318263, 0.10011774, 0.10923475,\n",
       "        0.0953856 , 0.07673422, 0.08127728, 0.10381038, 0.09508047,\n",
       "        0.09865127, 0.10766276, 0.09612275, 0.09531775, 0.10012512,\n",
       "        0.10521134, 0.1       , 0.10841236, 0.1       , 0.1       ,\n",
       "        0.1       ],\n",
       "       [0.11257514, 0.09561734, 0.1       , 0.08724317, 0.09503871,\n",
       "        0.1045772 , 0.10458529, 0.10496358, 0.09557008, 0.08042086,\n",
       "        0.10336471, 0.09511368, 0.09052376, 0.10741582, 0.10820424,\n",
       "        0.11695656, 0.1095827 , 0.11860549, 0.1       , 0.10023895,\n",
       "        0.09610928, 0.1       , 0.09994707, 0.1       , 0.1       ,\n",
       "        0.1       ],\n",
       "       [0.11096236, 0.09558135, 0.1       , 0.10172013, 0.09631868,\n",
       "        0.10427667, 0.09496987, 0.09475674, 0.0821151 , 0.10543526,\n",
       "        0.0773196 , 0.09586756, 0.0953447 , 0.07569475, 0.09116458,\n",
       "        0.11212157, 0.11170822, 0.09504424, 0.10180242, 0.09709274,\n",
       "        0.10489942, 0.1       , 0.1049011 , 0.1       , 0.1       ,\n",
       "        0.1       ],\n",
       "       [0.08309444, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "        0.10498247, 0.1097569 , 0.09606371, 0.11928098, 0.09578598,\n",
       "        0.11038177, 0.11454387, 0.10499719, 0.12392223, 0.10018936,\n",
       "        0.11028233, 0.09042048, 0.1145759 , 0.09104531, 0.10451206,\n",
       "        0.1049755 , 0.1       , 0.10488808, 0.1       , 0.1       ,\n",
       "        0.07956922],\n",
       "       [0.1       , 0.1       , 0.1       , 0.10611564, 0.1       ,\n",
       "        0.10828657, 0.08719616, 0.10062068, 0.11407601, 0.10881026,\n",
       "        0.10320446, 0.11018905, 0.11836489, 0.1197174 , 0.11144965,\n",
       "        0.10938356, 0.10019451, 0.10990432, 0.10490371, 0.10001   ,\n",
       "        0.10896963, 0.1       , 0.09990366, 0.1       , 0.1       ,\n",
       "        0.1       ],\n",
       "       [0.09044949, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "        0.09145074, 0.1       , 0.09475913, 0.09500827, 0.09233453,\n",
       "        0.10155761, 0.10465547, 0.09501947, 0.09523097, 0.10476342,\n",
       "        0.09899708, 0.1       , 0.09621768, 0.10194859, 0.1       ,\n",
       "        0.10479883, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "        0.08925004],\n",
       "       [0.09673673, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "        0.09521397, 0.09501974, 0.10046938, 0.10012786, 0.09988878,\n",
       "        0.09872929, 0.10499002, 0.11486994, 0.10493253, 0.09549967,\n",
       "        0.10218193, 0.10177279, 0.10258706, 0.09656441, 0.1       ,\n",
       "        0.10496026, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "        0.1       ],\n",
       "       [0.11030957, 0.09024443, 0.08308688, 0.1       , 0.1       ,\n",
       "        0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "        0.1       , 0.1       , 0.09501993, 0.09553973, 0.1       ,\n",
       "        0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "        0.0950651 , 0.1       , 0.1       , 0.0895663 , 0.1       ,\n",
       "        0.12501756]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
