{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validity_check(image, conv_filter, padding, stride):\n",
    "    \n",
    "    is_valid = True\n",
    "    image_shape = (np.shape(image))\n",
    "    \n",
    "    filter_shape = (np.shape(conv_filter))\n",
    "    \n",
    "    \n",
    "    if len(image_shape) != len(filter_shape) - 1:\n",
    "        print('Dimensions of both image and filter should be equal')\n",
    "        is_valid = False\n",
    "    \n",
    "    if len(image_shape) >= 3 or len(filter_shape) > 3:\n",
    "        if image_shape[-1] != filter_shape[-1]:\n",
    "            print('Number of channels in both image and filter should be equal')\n",
    "            is_valid = False\n",
    "        \n",
    "    if filter_shape[1] != filter_shape[2]:\n",
    "        print(\"Filter should be of a square matrix\")\n",
    "        is_valid = False\n",
    "        \n",
    "        \n",
    "\n",
    "    if filter_shape[1] % 2 == 0:\n",
    "        print('dimensions of filter should be of odd dimensions not even')\n",
    "        is_valid = False\n",
    "    \n",
    "\n",
    "    '''\n",
    "    convolution_result is the array we obtain after running the filter all over the image\n",
    "    '''    \n",
    "    if is_valid:\n",
    "        '''one or more filters but only one channel (also for image)'''\n",
    "        if len(image_shape) == 2 and len(filter_shape) == 3:\n",
    "            \n",
    "            convolution_result = np.zeros((\n",
    "                            np.int16(((image_shape[0] + 2 * padding - filter_shape[1]) / stride) + 1),\n",
    "                            np.int16(((image_shape[1] + 2 * padding - filter_shape[2]) / stride) + 1)))\n",
    "            \n",
    "        '''one or more filters with more than one channel (also for image)'''\n",
    "        if len(image_shape) == 3 and len(filter_shape) == 4:\n",
    "            convolution_result = np.zeros((\n",
    "                            np.int16(((image_shape[0] + 2 * padding - filter_shape[1]) / stride) + 1),\n",
    "                            np.int16(((image_shape[1] + 2 * padding - filter_shape[2]) / stride) + 1),\n",
    "                            image_shape[3]))\n",
    "    else:\n",
    "        convolution_result = -1\n",
    "    \n",
    "    return [is_valid, convolution_result]\n",
    "\n",
    "\n",
    "def Relu(x):\n",
    "    indices = np.where(x < 0)\n",
    "    x[indices] = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The dimensions represent height, width and no_of_channels in the input image and filters\n",
    "'''\n",
    "\n",
    "\n",
    "class Conv_pool:\n",
    "    \n",
    "    def __init__(self, image, conv_filter, padding, stride, pooling_filter_size, pooling_filter_stride):\n",
    "        self.curr_image         = image\n",
    "        self.conv_filter        = conv_filter\n",
    "        self.conv_filter_stride = stride\n",
    "        self.pool_filter_size   = pooling_filter_size\n",
    "        self.pool_filter_stride = pooling_filter_stride\n",
    "        self.padding            = padding\n",
    "        self.conv_result        = np.array([])\n",
    "        self.relu_result        = np.array([])\n",
    "        self.pooling_result     = np.array([])\n",
    "            \n",
    "\n",
    "    ######################################################\n",
    "    \n",
    "    def start_convolving_the_image(self, convolution_result):\n",
    "        image = self.curr_image\n",
    "        conv_filter = self.conv_filter\n",
    "        stride = self.conv_filter_stride\n",
    "        convoluted_image_list = []\n",
    "\n",
    "        image_shape = np.shape(image)\n",
    "        filter_shape = np.shape(conv_filter)\n",
    "\n",
    "        no_of_filters = filter_shape[0]\n",
    "\n",
    "        '''this loop runs for all the different filters in the conv_filter'''\n",
    "        for filter_num in range(0, no_of_filters):\n",
    "            convoluted_image = np.array([])\n",
    "            filter_ = conv_filter[filter_num, :]\n",
    "    \n",
    "            '''if image has more than one channel'''\n",
    "            if len(image_shape) > 2 and image_shape[-1] == filter_shape[-1]:\n",
    "\n",
    "                convoluted_image = self.convolve_the_image_by_filter(image[:, :, 0], filter_[:, :, 0], \n",
    "                                                                   convolution_result)\n",
    "                for channel in range(1, filter_shape[-1]):\n",
    "                    convoluted_image = convoluted_image + self.convolve_the_image_by_filter(image[:, :, channel], filter_[:, :, channel],\n",
    "                                                                convolution_result)\n",
    "            '''if image has only one channel'''\n",
    "            if len(image_shape) == 2:\n",
    "                convoluted_image = self.convolve_the_image_by_filter(image, filter_, convolution_result)\n",
    "            '''here, you used copy.copy() so as to refrain the convoluted_image_list getting over-written\n",
    "            by the new entries into the list'''\n",
    "            convoluted_image_list.append(copy.copy(convoluted_image))\n",
    "\n",
    "        self.conv_result = np.array(convoluted_image_list)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    ######################################################\n",
    "    \n",
    "    def convolve_the_image_by_filter(self, image, conv_filter, convolution_result):\n",
    "        stride = self.conv_filter_stride\n",
    "        image_shape = np.shape(image)    \n",
    "        filter_size = np.shape(conv_filter)[0]\n",
    "        row_count = 0\n",
    "        column_count = 0\n",
    "        for row in range(0, image_shape[0], stride):\n",
    "            if row + filter_size <= image_shape[0]:\n",
    "                column_count = 0\n",
    "                for column in range(0, image_shape[1], stride):\n",
    "\n",
    "                    if column + filter_size <= image_shape[1]:\n",
    "\n",
    "                        '''present active region is the region in the image which will be multiplied\n",
    "                        by the filter'''\n",
    "                        present_active_region = image[row : (row + filter_size), column : (column + filter_size)]\n",
    "                        '''element-wise multiplication between image region and filter'''\n",
    "                        image_area_product_filter = present_active_region * conv_filter\n",
    "                        sum_of_all_elements = np.sum(image_area_product_filter)\n",
    "\n",
    "                        convolution_result[row_count, column_count] = sum_of_all_elements\n",
    "                        column_count = column_count + 1\n",
    "            row_count = row_count + 1\n",
    "\n",
    "        return convolution_result\n",
    "\n",
    "    \n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    def relu_on_convolution_result(self):\n",
    "        convolution_result_ = self.conv_result\n",
    "        relu_result_list = []\n",
    "        no_of_times_image_convoluted = np.shape(convolution_result_)[0]\n",
    "\n",
    "        for result_num in range(0, no_of_times_image_convoluted):\n",
    "            current_convoluted_image = convolution_result_[result_num, :]\n",
    "            relu_result_list.append(Relu(current_convoluted_image))\n",
    "\n",
    "        self.relu_result = np.array(relu_result_list)\n",
    "\n",
    "        \n",
    "    ######################################################\n",
    "    \n",
    "    '''max pooling'''    \n",
    "    def pooling_on_relu_result(self):\n",
    "        relu_result = self.relu_result\n",
    "        pool_size = self.pool_filter_size\n",
    "        stride_length = self.pool_filter_stride\n",
    "        pooling_result_list = []\n",
    "        no_of_relu_results = np.shape(relu_result)[0]\n",
    "        row_count = 0\n",
    "        column_count = 0\n",
    "        relu_result_shape = np.shape(relu_result)[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for relu_result_num in range(0, no_of_relu_results):\n",
    "            pooling_result = np.zeros((np.uint16(((relu_result_shape - pool_size) / stride_length) + 1),\n",
    "                                   np.uint16(((relu_result_shape - pool_size) / stride_length) + 1)))\n",
    "            curr_relu_result = relu_result[relu_result_num, :]\n",
    "            row_count = 0\n",
    "            for row in range(0, relu_result_shape, stride_length):\n",
    "                if row + pool_size <= relu_result_shape:\n",
    "                    column_count = 0\n",
    "                    for column in range(0, relu_result_shape, stride_length):\n",
    "                        if column + pool_size <= relu_result_shape:\n",
    "                            active_region = curr_relu_result[row : (row + pool_size), column : (column + pool_size)]\n",
    "                            pooling_result[row_count, column_count] = np.max(active_region)\n",
    "                            column_count = column_count + 1\n",
    "\n",
    "                row_count = row_count + 1\n",
    "            pooling_result_list.append(pooling_result)\n",
    "\n",
    "\n",
    "        self.pooling_result = np.array(pooling_result_list)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    ######################################################\n",
    "    \n",
    "    def CNN(self):\n",
    "    \n",
    "        validity_convolution_result = validity_check(self.curr_image, self.conv_filter, self.padding, self.conv_filter_stride)\n",
    "\n",
    "        if validity_convolution_result[0]:\n",
    "            convolution_result = validity_convolution_result[1]\n",
    "            self.start_convolving_the_image(convolution_result)\n",
    "            self.relu_on_convolution_result()\n",
    "            self.pooling_on_relu_result()\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu(x):\n",
    "    return x * (x > 0)\n",
    "    \n",
    "def softmax(x):\n",
    "    x = x.reshape(1, -1)\n",
    "    \n",
    "    max_item = np.max(x)\n",
    "    print('max is ' + str(max_item))\n",
    "    exp_x = np.exp(x - max_item)\n",
    "    res = np.true_divide(exp_x, np.sum(exp_x))\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def cross_entropy(output, labels):\n",
    "    return -np.sum(labels * np.log(output))\n",
    "\n",
    "\n",
    "\n",
    "class fully_connected_layers_in_CNN:\n",
    "    def __init__(self, conv_pool_object, labels, no_of_neurons):\n",
    "        self.conv_pool_result = conv_pool_object\n",
    "        self.pooling_result = conv_pool_object.pooling_result\n",
    "        self.labels = labels\n",
    "        self.pooling_result_shape = np.shape(self.pooling_result)\n",
    "        self.neurons = no_of_neurons\n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def feed_forward_in_fc_layers(self):\n",
    "        pooling_result = self.pooling_result\n",
    "        no_of_neurons = self.neurons\n",
    "        no_of_pool_results, no_of_rows, no_of_columns = self.pooling_result_shape\n",
    "        self.fc_layer_1 = pooling_result.reshape(((no_of_pool_results * no_of_rows * no_of_columns), 1))\n",
    "        \n",
    "        no_of_rows_in_fc_layer_1 = self.fc_layer_1.shape[0]\n",
    "        self.weights_1 = np.random.random((no_of_neurons[0], no_of_rows_in_fc_layer_1))\n",
    "        self.bias_1 = np.zeros(shape = (no_of_neurons[0], 1))\n",
    "        \n",
    "        self.z_1 = np.add(np.dot(self.weights_1, self.fc_layer_1), self.bias_1)\n",
    "        print(np.shape(self.z_1))\n",
    "        self.fc_layer_2 = Relu(self.z_1)\n",
    "        \n",
    "        no_of_rows_in_fc_layer_2 = self.fc_layer_2.shape[0]\n",
    "        self.weights_2 = np.random.random((no_of_neurons[1], no_of_rows_in_fc_layer_2))\n",
    "        self.bias_2 = np.zeros(shape = (no_of_neurons[1], 1))\n",
    "        \n",
    "        self.z_2 = np.add(np.dot(self.weights_2, self.fc_layer_2), self.bias_2)\n",
    "        \n",
    "        self.predicted_probs = softmax(self.z_2)\n",
    "        print('pr ' + str(self.predicted_probs))\n",
    "        self.loss = cross_entropy(self.predicted_probs, self.labels)\n",
    "        self.diff_between_pred_and_actual_labels = self.predicted_probs - self.labels\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class back_propagation_in_CNN:\n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def __init__(self, fc_layer_object):\n",
    "        self.fc_layer_object = fc_layer_object\n",
    "        self.conv_pool_result = fc_layer_object.conv_pool_result\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def get_the_index(self, conv_sub_array):\n",
    "        position_of_max_element = np.nanargmax(conv_sub_array)\n",
    "        index_of_max_element = np.unravel_index(position_of_max_element, conv_sub_array.shape)\n",
    "        return index_of_max_element\n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def backpropagation_wrt_pooling_result(self, derivative_pool_result):\n",
    "        \n",
    "        \n",
    "        conv_result = self.conv_pool_result.conv_result\n",
    "        pool_filter_size = self.conv_pool_result.pool_filter_size\n",
    "        pool_filter_stride = self.conv_pool_result.pool_filter_stride\n",
    "        \n",
    "        no_of_convolved_images, no_of_rows, no_of_columns = np.shape(conv_result)\n",
    "        _, pool_row_length, _ = np.shape(derivative_pool_result)\n",
    "        output = np.zeros(shape = np.shape(conv_result))\n",
    "    \n",
    "        row_count = 0\n",
    "        column_count = 0\n",
    "        for image_num in range(0, no_of_convolved_images):\n",
    "            current_image = conv_result[image_num, :]\n",
    "            row_count = 0\n",
    "            for row in range(0, no_of_rows, pool_filter_stride):\n",
    "                if row + pool_filter_size <= no_of_rows:\n",
    "                    column_count = 0\n",
    "                    for column in range(0, no_of_columns, pool_filter_stride):\n",
    "                        if column + pool_filter_size <= no_of_columns:\n",
    "                            image_sub_array = current_image[row : row + pool_filter_size, column : column + pool_filter_size]\n",
    "                            '''index of the max element in the original conv_image (in the area covered by pool filter)'''\n",
    "                            (i, j) = self.get_the_index(image_sub_array)\n",
    "                            if row_count <= pool_row_length:\n",
    "                                output[image_num, row + i, column + j] = derivative_pool_result[image_num, \n",
    "                                                                                            row_count, column_count]\n",
    "                            column_count = column_count + 1\n",
    "                \n",
    "                row_count = row_count + 1\n",
    "            \n",
    "        return output\n",
    "                              \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def backpropagation_wrt_convolution_layer(self, der_conv_prev):\n",
    "                \n",
    "        conv_curr_image = self.conv_pool_result.curr_image\n",
    "        conv_image_curr_list = [conv_curr_image]\n",
    "        conv_image_curr = np.array(conv_image_curr_list)\n",
    "        conv_filter = self.conv_pool_result.conv_filter\n",
    "        filter_stride = self.conv_pool_result.conv_filter_stride\n",
    "        no_of_filters, flt_size, no_of_columns_f = np.shape(conv_filter)\n",
    "        \n",
    "        len_of_shape_of_curr_image = len(np.shape(conv_image_curr))\n",
    "        \n",
    "        _,no_of_rows, no_of_columns = np.shape(conv_image_curr)\n",
    "\n",
    "        \n",
    "        der_wrt_filter = np.zeros(np.shape(conv_filter))\n",
    "        der_wrt_bias = np.zeros((no_of_filters, 1))\n",
    "        dconv_result = np.zeros(np.shape(conv_image_curr))\n",
    "        \n",
    "        r_count = 0\n",
    "        c_count = 0\n",
    "        \n",
    "        for filter_num in range(0, no_of_filters, filter_stride):\n",
    "            r_count = 0\n",
    "            for r in range(0, no_of_rows):\n",
    "                if r + flt_size <= no_of_rows:\n",
    "                    c_count = 0\n",
    "                    for c in range(0, no_of_columns, filter_stride):\n",
    "                        if c + flt_size <= no_of_columns:\n",
    "                            '''update the filter'''\n",
    "                            \n",
    "                            der_wrt_filter += der_conv_prev[filter_num, r_count, c_count] * conv_image_curr[:, \n",
    "                                                                                                         r : r + flt_size,\n",
    "                                                                                                         c : c + flt_size]\n",
    "                            \n",
    "                            dconv_result[:, r : r + flt_size, c : c + flt_size] += der_conv_prev[filter_num, r_count, c_count] * conv_filter[filter_num, :]\n",
    "                            \n",
    "                            c_count = c_count + 1\n",
    "                r_count = r_count + 1\n",
    "        \n",
    "            der_wrt_bias[filter_num] = np.sum(der_conv_prev[filter_num])\n",
    "        \n",
    "        \n",
    "        return dconv_result, der_wrt_filter, der_wrt_bias\n",
    "                                \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    \n",
    "    def start_back_propagation(self):\n",
    "        fc_layer_object = self.fc_layer_object\n",
    "        fc_layer_1 = fc_layer_object.fc_layer_1\n",
    "        self.derivative_wrt_weights_2  = np.dot(fc_layer_object.diff_between_pred_and_actual_labels.T, \n",
    "                                                       fc_layer_object.z_1.T)\n",
    "        \n",
    "        temporary_result = np.dot(fc_layer_object.weights_2.T,  \n",
    "                                                    fc_layer_object.diff_between_pred_and_actual_labels.T)\n",
    "        \n",
    "        print(fc_layer_object.fc_layer_1)\n",
    "        self.derivative_wrt_weights_1 = np.dot(temporary_result,\n",
    "                                                  fc_layer_object.fc_layer_1.T)\n",
    "        \n",
    "        self.derivative_wrt_bias_2 = np.sum(fc_layer_object.diff_between_pred_and_actual_labels, \n",
    "                                                axis = 1).T\n",
    "        self.derivative_wrt_bias_1 = np.sum(temporary_result, axis = 1).reshape(fc_layer_object.bias_1.shape)\n",
    "        \n",
    "        \n",
    "        der_fc_layer_1 = np.dot(fc_layer_object.weights_1.T, temporary_result)\n",
    "        reshaped_dfc_layer_1 = der_fc_layer_1.reshape(fc_layer_object.pooling_result_shape)\n",
    "        '''back propagating through max-pooling layer (updating only those neurons with highest value)'''\n",
    "        der_pool_layer = self.backpropagation_wrt_pooling_result(reshaped_dfc_layer_1)\n",
    "        \n",
    "        '''back propagating through Relu layer'''\n",
    "        der_pool_layer[fc_layer_object.conv_pool_result.conv_result <= 0] = 0\n",
    "        \n",
    "        der_image, der_filter, der_conv_bias = self.backpropagation_wrt_convolution_layer(der_pool_layer)\n",
    "        \n",
    "        self.return_result = [der_filter, der_conv_bias ]\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
